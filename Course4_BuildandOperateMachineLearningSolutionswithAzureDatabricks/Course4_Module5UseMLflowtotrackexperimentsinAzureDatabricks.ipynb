{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc_79hyqeW1G"
   },
   "source": [
    "**<center><h1>Introduction</h1></center>**\n",
    "\n",
    "When doing machine learning tasks in Azure Databricks, you can use MLflow to track and review your work. In this module, you will learn what MLflow is and how you can use its various features.\n",
    "\n",
    "\n",
    "**<h2>Learning Objectives</h2>**\n",
    "\n",
    "After completing this module, youâ€™ll be able to:\n",
    "\n",
    "- Describe the capabilities of MLflow.\n",
    "- Describe MLflow terms.\n",
    "- Start a run in MLflow.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqBhKivuvUk"
   },
   "source": [
    "**<center><h1>Understand capabilities of MLflow</h1></center>**\n",
    "\n",
    "**MLflow** is an open-source product designed to manage the Machine Learning development lifecycle. That is, MLflow allows data scientists to train models, register those models, deploy the models to a web server, and manage model updates.\n",
    "\n",
    "\n",
    "**<h2>The importance of MLflow</h2>**\n",
    "\n",
    "MLflow is an important part of machine learning with Azure Databricks, as it integrates key operational processes with the Azure Databricks interface. MLflow makes it easy for data scientists to train models and make them available without writing a great deal of code.\n",
    "\n",
    "As a side note, MLflow will also operate on workloads outside of Azure Databricks. The examples in this module will all use Azure Databricks but this is not a requirement.\n",
    "\n",
    "**<h2>MLflow product components</h2>**\n",
    "\n",
    "There are four components to MLflow:\n",
    "\n",
    "- MLflow Tracking\n",
    "- MLflow Projects\n",
    "- MLflow Models\n",
    "- MLflow Model Registry\n",
    "\n",
    "**<h2>MLflow Tracking</h2>**\n",
    "\n",
    "MLflow Tracking allows data scientists to work with experiments. For each run in an experiment, a data scientist may log parameters, versions of libraries used, evaluation metrics, and generated output files when training machine learning models.\n",
    "\n",
    "MLflow Tracking provides the ability to audit the results of prior model training executions.\n",
    "\n",
    "\n",
    "<img src=\"images/03-01-01-parameters.png\" />\n",
    "\n",
    "\n",
    "**<h2>MLflow Projects</h2>**\n",
    "\n",
    "An MLflow Project is a way of packaging up code in a manner, which allows for consistent deployment and the ability to reproduce results. MLflow supports several environments for projects, including via Conda, Docker, and directly on a system.\n",
    "\n",
    "\n",
    "**<h2>MLflow Models</h2>**\n",
    "\n",
    "MLflow offers a standardized format for packaging models for distribution. This standardized model format allows MLflow to work with models generated from several popular libraries, including ```scikit-learn```, ```Keras```, ```MLlib```, ```ONNX```, and more. Review the [MLflow Models documentation](https://mlflow.org/docs/latest/models.html) for information on the full set of supported model flavors.\n",
    "\n",
    "**<h2>MLflow Model Registry</h2>**\n",
    "\n",
    "The MLflow Model Registry allows data scientists to register models in a registry.\n",
    "\n",
    "<img src=\"images/03-01-01-registry.png\" />\n",
    "\n",
    "From there, MLflow Models and MLflow Projects combine with the MLflow Model Registry to allow operations team members to deploy models in the registry, serving them either through a REST API or as part of a batch inference solution using Azure Databricks.\n",
    "\n",
    "<img src=\"images/03-01-01-deploy.png\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AOYGD4704w4"
   },
   "source": [
    "**<center><h1>Use MLflow terminology</h1></center>**\n",
    "\n",
    "There are several terms, which will be important to understand when working with MLflow. Most of these terms are fairly common in the data science space. Other products, such as Azure Machine Learning, use very similar terminology to allow for simplified cross-product development of skills. The following sections include key terms and concepts for each MLflow product.\n",
    "\n",
    "**<h2>MLflow Tracking</h2>**\n",
    "\n",
    "MLflow Tracking is built around **runs**, that is, executions of code for a data science task. Each run contains several key attributes, including:\n",
    "\n",
    "- **Parameters:** Key-value pairs, which represent inputs. Use parameters to track **hyperparameters**, that is, inputs to functions, which affect the machine learning process.\n",
    "- **Metrics:** Key-value pairs, which represent how the model is performing. This can include evaluation measures such as Root Mean Square Error, and metrics can be updated throughout the course of a run. This allows a data scientist, for example, to track Root Mean Square Error for each epoch of a neural network.\n",
    "- **Artifacts:** Output files. Artifacts may be stored in any format, and can include models, images, log files, data files, or anything else, which might be important for model analysis and understanding.\n",
    "\n",
    "These runs can be combined together into **experiments**, which are intended to collect and organize runs. For example, a data scientist may create an experiment to train a classifier against a particular data set. Each run might try a different algorithm or different set of inputs. The data scientist can then review the individual runs in order to determine which run generated the best model.\n",
    "\n",
    "**<h2>MLflow Projects</h2>**\n",
    "\n",
    "A project in MLflow is a method of packaging data science code. This allows other data scientists or automated processes to use the code in a consistent manner.\n",
    "\n",
    "Each project includes at least one **entry point**, which is a file (either **.py** or **.sh**) that is intended to act as the starting point for project use. Projects also specify details about the **environment**. This includes the specific packages (and versions of packages) used in developing the project, as new versions of packages may include breaking changes.\n",
    "\n",
    "**<h2>MLflow Models</h2>**\n",
    "\n",
    "A **model** in MLflow is a directory containing an arbitrary set of files along with an MLmodel file in the root of the directory.\n",
    "\n",
    "MLflow allows models to be of a particular **flavor**, which is a descriptor of which tool or library generated a model. This allows MLflow to work with a wide variety of modeling libraries, such as ```scikit-learn```, ```Keras```, ```MLlib```, ```ONNX```, and many more. Each model has a **signature**, which describes the expected inputs and outputs for the model.\n",
    "\n",
    "**<h2>MLflow Model Registry</h2>**\n",
    "The MLflow Model Registry allows a data scientist to keep track of a **model** from MLflow Models. In other words, the data scientist **registers** a model with the Model Registry, storing details such as the name of the model. Each registered model may have multiple **versions**, which allow a data scientist to keep track of model changes over time.\n",
    "\n",
    "It is also possible to **stage** models. Each model version may be in one stage, such as **Staging, Production, or Archived**. Data scientists and administrators may **transition** a model version from one stage to the next.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exJkxNHb05Kv"
   },
   "source": [
    "**<center><h1>Run experiments</h1></center>**\n",
    "\n",
    "MLflow experiments allow data scientists to track training runs in a collection called an **experiment**. This is useful for comparing changes over time or comparing the relative performance of models with different hyperparameter values.\n",
    "\n",
    "Creating an experiment in Azure Databricks happens automatically when you start a run. Here is an example of starting a run in MLflow, logging two parameters, and logging one metric:\n",
    "\n",
    "```\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"input1\", input1)\n",
    "    mlflow.log_param(\"input2\", input2)\n",
    "    # Perform operations here like model training.\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "In this case, the experiment's name will be the name of the notebook. It is possible to export a variable named ```MLFLOW_EXPERIMENT_NAME``` to change the name of your experiment should you choose.\n",
    "\n",
    "\n",
    "**<h2>Reviewing Experiments</h2>**\n",
    "\n",
    "Inside a notebook, the **Experiment** menu option displays a context bar, which includes information on runs of the current experiment.\n",
    "<img src=\"images/03-01-03-experiment.png\" />\n",
    "Selecting the External Link icon in the experiment run will provide additional details on a particular run.\n",
    "<img src=\"images/03-01-03-external-link.png\" />\n",
    "This link will provide the information that MLflow Tracker logged, including notes, parameters, metrics, tags, and artifacts.\n",
    "<img src=\"images/03-01-03-run.png\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJny5sl05Yf"
   },
   "source": [
    "**<center><h1>Exercise - Use MLflow to track an experiment</h1></center>**\n",
    "\n",
    "Now, it's your chance to use Azure Databricks and MLflow to run an experiment and track the results of different experimental tests.\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "- Running an experiment.\n",
    "- Reviewing experiment metrics.\n",
    "\n",
    "**<h2>Instructions</h2>**\n",
    "\n",
    "Follow these instructions to complete the exercise:\n",
    "\n",
    "1. Open the exercise instructions at https://aka.ms/mslearn-dp090.\n",
    "2, Complete the **Using MLflow to Track Experiments** exercise.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course4_Module4UseMLflowtotrackexperimentsinAzureDatabricks",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
