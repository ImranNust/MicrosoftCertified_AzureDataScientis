{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc_79hyqeW1G"
   },
   "source": [
    "**<center><h1>Introduction</h1></center>**\n",
    "\n",
    "\n",
    "If you choose to train models using Azure Databricks and track your work using MLflow, you can add an integration with Azure Machine Learning to store model training metrics and artifacts and keep a clear overview of your work. Using Azure Machine Learning as the backend for your MLflow experiments that run on Azure Databricks compute gives you the benefit of having a centralized and scalable workspace where you can access all your assets to run experiments or review them. In this module, you will learn about the integration between all these products and how you can manage your work from the Azure Machine Learning workspace.\n",
    "\n",
    "**<h2>Learning Objectives</h2>**\n",
    "\n",
    "After completing this module, you'll be able to:\n",
    "\n",
    "- Describe Azure Machine Learning.\n",
    "- Run an experiment.\n",
    "- Log metrics with MLflow.\n",
    "- Run Pipeline Step on Databricks Compute.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqBhKivuvUk"
   },
   "source": [
    "**<center><h1>Describe Azure Machine Learning</h1></center>**\n",
    "\n",
    "Azure Machine Learning is a platform for operating machine learning workloads in the cloud.\n",
    "\n",
    "<img src=\"images/04-01-01-what-azure-machine-learning.jpg\" />\n",
    "\n",
    "Built on the Microsoft Azure cloud platform, Azure Machine Learning enables you to manage:\n",
    "\n",
    "- Scalable on-demand compute for machine learning workloads.\n",
    "- Data storage and connectivity to ingest data from a wide range of sources.\n",
    "- Machine learning workflow orchestration to automate model training, deployment, and management processes.\n",
    "- Model registration and management, so you can track multiple versions of models and the data on which they were trained.\n",
    "- Metrics and monitoring for training experiments, datasets, and published services.\n",
    "-  Model deployment for real-time and batch inferencing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AOYGD4704w4"
   },
   "source": [
    "**<center><h1>Run Azure Databricks experiments in Azure Machine Learning</h1></center>**\n",
    "\n",
    "[MLflow](https://www.mlflow.org/) is an open-source library for managing the life cycle of your machine learning experiments. [MLFlow Tracking](https://mlflow.org/docs/latest/quickstart.html#using-the-tracking-api) is a component of MLflow that logs and tracks your training run metrics and model artifacts, no matter your experiment's environment.\n",
    "\n",
    "A recommended approach for running Azure Machine Learning (AML) Experiments on Azure Databricks cluster is to use MLflow Tracking and connect Azure Machine Learning as the backend for MLflow experiments.\n",
    "\n",
    "The following diagram illustrates that with MLflow Tracking, you track an experiment's run metrics and store model artifacts in your Azure Machine Learning workspace.\n",
    "\n",
    "<img src=\"images/04-01-02-mlflow-diagram.png\" />\n",
    "\n",
    "**<h2>Track AML Experiments in Azure Databricks</h2>**\n",
    "\n",
    "When running AML experiments in Azure Databricks, there are three key steps:\n",
    "\n",
    "1. Configure MLflow tracking URI to use AML.\n",
    "2. Configure a MLflow experiment.\n",
    "3. Run your experiment.\n",
    "\n",
    "\n",
    "\n",
    "**<h3>1. Configure MLflow tracking URI to use AML</h3>**\n",
    "\n",
    "In order to configure MLflow Tracking and connect Azure Machine Learning as the backend for MLFlow experiments, you need to follow these steps as shown in the code snippet:\n",
    "\n",
    "- Get your AML workspace object.\n",
    "- From your AML workspace object, get the unique tracking URI address.\n",
    "- Setup MLflow tracking URI to point to AML workspace.\n",
    "\n",
    "```\n",
    "import mlflow\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Get your AML workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Get the unique tracking URI address to the AML workspace\n",
    "tracking_uri = ws.get_mlflow_tracking_uri()\n",
    "\n",
    "# Set up MLflow tracking URI to point to AML workspace\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "```\n",
    "\n",
    "**<h3>2. Configure a MLflow experiment</h3>**\n",
    "\n",
    "Provide the name for the MLflow experiment as shown below. Note that the same experiment name will appear in Azure Machine Learning.\n",
    "```\n",
    "experiment_name = 'MLflow-AML-Exercise'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "```\n",
    "**<h3>3. Run your experiment</h3>**\n",
    "\n",
    "Once the experiment is set up, you can start your training run with ```start_run()``` as shown below:\n",
    "```\n",
    "with mlflow.start_run() as run:\n",
    "    ...\n",
    "    ...\n",
    "```\n",
    "Your model training and logging code are provided within the ```with``` block.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exJkxNHb05Kv"
   },
   "source": [
    "**<center><h1>Log metrics in Azure Machine Learning with MLflow</h1></center>**\n",
    "\n",
    "In the previous unit, we discussed how to set up Azure Machine Learning as the backend for MLflow experiments. We also looked at how to start your model training on Azure Databricks as a MLflow experiment. In this section, we will look at how to log model metrics and artifacts to the MLflow logging API. These logged metrics and artifacts are then captured in an Azure Machine Learning workspace that provides a centralized, secure, and scalable location to store training metrics and artifacts.\n",
    "\n",
    "In your MLflow experiment, once you train and evaluate your model, you can use the MLflow logging API, ```mlflow.log_metric()```, to start logging your model metrics as shown below:\n",
    "\n",
    "```\n",
    "with mlflow.start_run() as run:\n",
    "    ...\n",
    "    ...\n",
    "    # Make predictions on hold-out data\n",
    "    y_predict = clf.predict(X_test)\n",
    "    y_actual = y_test.values.flatten().tolist()\n",
    "\n",
    "    # Evaluate and log model metrics on hold-out data\n",
    "    rmse = math.sqrt(mean_squared_error(y_actual, y_predict))\n",
    "    mlflow.log_metric('rmse', rmse)\n",
    "    mae = mean_absolute_error(y_actual, y_predict)\n",
    "    mlflow.log_metric('mae', mae)\n",
    "    r2 = r2_score(y_actual, y_predict)\n",
    "    mlflow.log_metric('R2 score', r2)\n",
    "```\n",
    "\n",
    "\n",
    "Next, you can use MLflowâ€™s ```log_artifact()``` API to save model artifacts such as your Predicted vs True curve as shown:\n",
    "\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    ...\n",
    "    ...\n",
    "    plt.scatter(y_actual, y_predict)\n",
    "    plt.savefig(\"./outputs/results.png\")\n",
    "    mlflow.log_artifact(\"./outputs/results.png\")\n",
    "```\n",
    "\n",
    "**<h2>Reviewing experiment metrics and artifacts in Azure ML Studio</h2>**\n",
    "\n",
    "Since Azure Machine Learning is set up as the backend for MLflow experiments, you can review all the training metrics and artifacts from within the Azure Machine Learning Studio. From within the studio, navigate to the ```Experiments``` tab, and open the experiment run that corresponds to the MLflow experiment. In the ```Metrics``` tab of the run, you will observe the model metrics that were logged via MLflow tracking APIs.\n",
    "\n",
    "<img src=\"images/04-01-03-01-azure-machine-learning-metrics.png\" />\n",
    "\n",
    "Next, when you open the ```Outputs + logs``` tab you will observe the model artifacts that were logged via MLflow tracking APIs.\n",
    "\n",
    "<img src=\"images/04-01-03-01-azure-machine-learning-artifacts.png\" />\n",
    "\n",
    "In summary, using MLflow integration with Azure Machine Learning, you can run experiments in Azure Databricks and leverage Azure Machine Learning workspace capabilities of centralized, secure, and scalable solution to store model training metrics and artifacts.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJny5sl05Yf"
   },
   "source": [
    "**<center><h1>Run Azure Machine Learning pipelines on Azure Databricks compute</h1></center>**\n",
    "\n",
    "Azure Machine Learning supports multiple types of compute for experimentation and training. Specifically, you can run an **Azure Machine Learning pipeline** on Databricks compute.\n",
    "\n",
    "**<h2>What is an Azure Machine Learning pipeline?</h2>**\n",
    "\n",
    "In Azure Machine Learning, a pipeline is a workflow of machine learning tasks in which each task is implemented as a step. Steps can be arranged sequentially or in parallel, enabling you to build sophisticated flow logic to orchestrate machine learning operations. Each step can be run on a specific compute target, making it possible to combine different types of processing as required to achieve an overall goal.\n",
    "\n",
    "**<h2>Running pipeline step on Databricks Compute</h2>**\n",
    "\n",
    "Azure Machine Learning supports a specialized pipeline step called DatabricksStep with which you can run a notebook, script, or compiled JAR on an Azure Databricks cluster. In order to run a pipeline step on a Databricks cluster, you need to do the following steps:\n",
    "\n",
    "1. Attach Azure Databricks Compute to Azure Machine Learning workspace.\n",
    "2. Define DatabricksStep in a pipeline.\n",
    "3. Submit the pipeline.\n",
    "\n",
    "**<h3>Attaching Azure Databricks Compute</h3>**\n",
    "\n",
    "The following code example can be used to attach an existing Azure Databricks cluster:\n",
    "```\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'db_cluster'\n",
    "\n",
    "# Define configuration for existing Azure Databricks cluster\n",
    "db_workspace_name = 'db_workspace'\n",
    "db_resource_group = 'db_resource_group'\n",
    "# Get the access token from the Databricks workspace\n",
    "db_access_token = '1234-abc-5678-defg-90...' \n",
    "db_config = DatabricksCompute.attach_configuration(resource_group=db_resource_group,\n",
    "                                                   workspace_name=db_workspace_name,\n",
    "                                                   access_token=db_access_token)\n",
    "\n",
    "# Create the compute\n",
    "databricks_compute = ComputeTarget.attach(ws, compute_name, db_config)\n",
    "databricks_compute.wait_for_completion(True)\n",
    "```\n",
    "\n",
    "**<h3>Defining DatabricksStep in a pipeline</h3>**\n",
    "\n",
    "To create a pipeline, you must first define each step and then create a pipeline that includes the steps. The specific configuration of each step depends on the step type. For example, the following code defines a **DatabricksStep** step to run a python script, ```process_data.py```, on the attached Databricks compute.\n",
    "```\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import DatabricksStep\n",
    "\n",
    "script_directory = \"./scripts\"\n",
    "script_name = \"process_data.py\"\n",
    "\n",
    "dataset_name = \"nyc-taxi-dataset\"\n",
    "\n",
    "spark_conf = {\"spark.databricks.delta.preview.enabled\": \"true\"}\n",
    "\n",
    "databricksStep = DatabricksStep(name = \"process_data\", \n",
    "                                run_name = \"process_data\", \n",
    "                                python_script_params=[\"--dataset_name\", dataset_name],  \n",
    "                                spark_version = \"7.3.x-scala2.12\", \n",
    "                                node_type = \"Standard_DS3_v2\", \n",
    "                                spark_conf = spark_conf, \n",
    "                                num_workers = 1, \n",
    "                                python_script_name = script_name, \n",
    "                                source_directory = script_directory,\n",
    "                                pypi_libraries = [PyPiLibrary(package = 'scikit-learn'), \n",
    "                                                  PyPiLibrary(package = 'scipy'), \n",
    "                                                  PyPiLibrary(package = 'azureml-sdk'), \n",
    "                                                  PyPiLibrary(package = 'azureml-dataprep[pandas]')], \n",
    "                                compute_target = databricks_compute, \n",
    "                                allow_reuse = False\n",
    "                               )\n",
    "```\n",
    "The above step defines the configuration to create a new Databricks job cluster to run the Python script. The cluster is created on the fly to run the script and the cluster is subsequently deleted after the step execution is completed.\n",
    "\n",
    "\n",
    "\n",
    "**<h3>Submit the pipeline</h3>**\n",
    "\n",
    "After defining the step, you can assign it to a pipeline, and run it as an experiment:\n",
    "```\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline(workspace = ws, steps = [databricksStep])\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = \"process-data-pipeline\")\n",
    "pipeline_run = experiment.submit(pipeline)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1B75umyJ05k3"
   },
   "source": [
    "**<center><h1>Exercise - Use Azure Databricks with Azure Machine Learning</h1></center>**\n",
    "\n",
    "Now, you will run experiments in Azure Machine Learning from Azure Databricks.\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "- Running an Azure ML experiment on Databricks.\n",
    "- Reviewing experiment metrics in Azure ML Studio.\n",
    "\n",
    "\n",
    "**<h2>Instructions</h2>**\n",
    "\n",
    "Follow these instructions to complete the exercise:\n",
    "\n",
    "1. Open the exercise instructions at https://aka.ms/mslearn-dp090.\n",
    "2. Complete the **Running experiments in Azure Machine Learning** exercises.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course4_Module7TrackAzureDatabricksexperimentsinAzureMachineLearning",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
