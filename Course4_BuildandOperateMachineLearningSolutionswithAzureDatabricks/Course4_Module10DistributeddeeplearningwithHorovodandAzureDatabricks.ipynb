{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course4_Module10DistributeddeeplearningwithHorovodandAzureDatabricks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Introduction</h1></center>**\n",
        "\n",
        "Azure Databricks supports Uber's Horovod framework to run distributed, deep learning training jobs on Spark.\n",
        "\n",
        "In this module, you'll learn how to distribute deep learning in Azure Databricks with HorovodRunner.\n",
        "\n",
        "\n",
        "**<h2>Learning Objectives</h2>**\n",
        "\n",
        "After completing this module, youâ€™ll be able to:\n",
        "\n",
        "- Understand what Horovod is and how it can help distribute your deep learning models.\n",
        "-Use HorovodRunner in Azure Databricks for distributed deep learning.\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "Wc_79hyqeW1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Understand Horovod</h1></center>**\n",
        "\n",
        "Horovod can help data scientists when training deep learning models. Before we can explore Horovod, let's review what deep learning is and what the problem with training deep learning models can be.\n",
        "\n",
        "**<h2>A quick review of deep learning</h2>**\n",
        "\n",
        "Deep learning is a subfield of machine learning and refers to models that consist of multiple layers, also known as deep neural networks. The training process starts with data being submitted to the input layer in **batches**.\n",
        "\n",
        "The data is analyzed by the input layer and passed on to the next layer until it reaches the output layer and produces a prediction. Predictions are compared to the actual known value and based on these results, weights, and bias values are revised to improve the model.\n",
        "\n",
        "Batches are processed by the network over multiple iterations or **epochs**. Each epoch, the model tries to further improve predictions by updating the weight and bias values.\n",
        "\n",
        "\n",
        "**<h2>Deep learning with Azure Databricks</h2>**\n",
        "\n",
        "Within Azure Databricks, we can train deep learning models using the popular open-source frameworks for Python: TensorFlow, PyTorch, and Keras. When we use any of these single-node frameworks to train a deep learning model, we should use a single-node cluster in Azure Databricks.\n",
        "\n",
        "Deep learning models benefit from having more data: the more data, the more likely it is we will get a better or more accurate model. Although it is advised to train deep learning models on single-node clusters, your model or your data may be too large to fit in the memory of a single machine. A single-node cluster being insufficient is the problem that data scientists may face when training deep learning models. Thankfully, Horovod can help in these scenarios.\n",
        "\n",
        "**<h2>Understand Horovod</h2>**\n",
        "\n",
        "Horovod is an open-source distributed training framework and is the alternative to training a model on a single-node cluster. Horovod allows data scientists to distribute the training process and make use of Spark's parallel processing.\n",
        "\n",
        "Since deep learning models contain layers that need to be processed sequentially, and use intermediary results to improve the model at the end of an epoch, the parallel processing of deep learning models can quickly become complicated. Horovod is designed to take care of the infrastructure management so that data scientists can focus on training models.\n",
        "\n",
        "Horovod is named after a traditional dance in which partners hold hands while dancing in a circle. Horovod owes this name to the way it allows worker nodes to communicate with other worker nodes, to avoid a bottle-neck at the driver node.\n",
        "\n",
        "When Horovod is used on top of one of the deep learning frameworks (TensorFlow, PyTorch or Keras), it trains multiple models on different batches of the input dataset on separate workers. In other words, multiple models are trained in parallel on separate workers using different subsets of the data.\n",
        "\n",
        "At the end of an epoch, the weights are communicated between workers and the average weight of all workers is calculated. Next, a new epoch can start using the new average weight and during which again, multiple models are trained in parallel.\n",
        "\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "nPqBhKivuvUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>HorovodRunner for distributed deep learning</h1></center>**\n",
        "\n",
        "You want to train deep learning models using the open-source frameworks TensorFlow, Keras, or PyTorch in Azure Databricks. You tried using a single-node cluster but your model or data is too large for the cluster. In that case, you may choose to use Horovod on top of your work so far to distribute the training. Let's explore how we can do that using **HorovodRunner**.\n",
        "\n",
        "**<h2>Trigger Horovod in Azure Databricks with HorovodRunner</h2>**\n",
        "\n",
        "HorovodRunner is a general API, which triggers Horovod jobs. The benefit of using HorovodRunner instead of the Horovod framework directly, is that HorovodRunner has been designed to distribute deep learning jobs across Spark workers. As a result, HorovodRunner is more stable for long-running deep learning training jobs on Azure Databricks.\n",
        "\n",
        "**<h2>Horovod process</h2>**\n",
        "\n",
        "To distribute the training of a deep learning model using HorovodRunner, you should do the following:\n",
        "\n",
        "- Prepare and test single-node code with TensorFlow, Keras, or PyTorch.\n",
        "- Migrate the code to Horovod.\n",
        "- Use HorovodRunner to run the code and distribute your work.\n",
        "\n",
        "**<h2>Run single-node training</h2>**\n",
        "\n",
        "Before working with Horovod and HorovodRunner, the code used to train the deep learning model should be tested on a single-node cluster. Once it works, make sure to wrap the main training procedure into a single Python function. This function will be used later on to initiate the distributed execution of your code.\n",
        "\n",
        "**<h2>Migrate to Horovod</h2>**\n",
        "\n",
        "Once you have tested your single-node code to train a deep learning model, you have to migrate it to Horovod before you can trigger the job with HorovodRunner.\n",
        "\n",
        "1. Import the Horovod framework as ```hvd```.\n",
        "2. Initialize the Horovod library with ```hvd.init()```.\n",
        "3. Pin one GPU per process. Pinning is necessary to disable random mapping of workers and avoid clashes. Pinning is skipped when using CPUs.\n",
        "4. Specify how you want to partition or sample the data so that each worker uses a unique subset of the data to train a model. As a best practice, make sure the subsets are all the same size. Depending on the input dataset, there are several techniques to do the sampling. For example, you could use Petastorm to work with datasets in Apache Parquet format. Learn more about the open-source library Petastorm [here](https://github.com/uber/petastorm).\n",
        "5. Scale the learning rate by the number of workers to make sure the weights are adjusted correctly after each epoch.\n",
        "6. Use the Horovod distributed optimizer to handle the communication between workers.\n",
        "7. Broadcast the initial parameters so al workers start with the same parameters.\n",
        "8. Save checkpoints only on worker 0 to prevent conflicts between workers.\n",
        "\n",
        "**<h2>Use HorovodRunner</h2>**\n",
        "\n",
        "To run HovorodRunner, you have to create a ```HorovodRunner``` instance in which you specify how many nodes (defined by the argument ```np```) you want to distribute your work to. You can specify to use one node if you want to test on a single-node cluster with ```np=-1```. Finally, you can trigger the Horovod training job with HorovodRunner by invoking the Python function you created for your training code.\n",
        "\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "2AOYGD4704w4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Exercise</h1></center>**\n",
        "\n",
        "Now, it's your chance to distribute deep learning in Azure Databricks.\n",
        "\n",
        "In this exercise, you will:\n",
        "\n",
        "- Run single-node training with PyTorch and migrate it to Horovod.\n",
        "- Distribute model training with HorovodRunner.\n",
        "\n",
        "**<h2>Instructions</h2>**\n",
        "\n",
        "Follow these instructions to complete the exercise:\n",
        "\n",
        "1. Open the exercise instructions at https://aka.ms/mslearn-dp090.\n",
        "2. Complete the **Distributed deep learning with Azure Databricks** exercise.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "exJkxNHb05Kv"
      }
    }
  ]
}