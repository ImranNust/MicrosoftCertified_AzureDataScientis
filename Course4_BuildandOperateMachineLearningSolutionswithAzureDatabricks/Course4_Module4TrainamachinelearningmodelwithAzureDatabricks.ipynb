{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc_79hyqeW1G"
   },
   "source": [
    "**<center><h1>Introduction</h1></center>**\n",
    "\n",
    "\n",
    "To train a machine learning model with Azure Databricks, data scientists can use the Spark ML library. In this module, you learn how to train and evaluate a machine learning model using the Spark ML library as well as other machine learning frameworks.\n",
    "\n",
    "**<h2>Learning Objectives</h2>**\n",
    "\n",
    "After completing this module, youâ€™ll be able to:\n",
    "\n",
    "- Describe Spark ML.\n",
    "- Train and validate a machine learning model.\n",
    "- Use other machine learning frameworks.\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqBhKivuvUk"
   },
   "source": [
    "**<center><h1>Understand Spark ML</h1></center>**\n",
    "\n",
    "Azure Databricks supports several libraries for machine learning. There's one key library, which has two approaches that are native to Apache Spark: **MLLib** and **Spark ML**.\n",
    "\n",
    "\n",
    "**<h2>MLLib</h2>**\n",
    "\n",
    "MLLib is a legacy approach for machine learning on Apache Spark. It builds off of Spark's [Resilient Distributed Dataset](https://spark.apache.org/docs/latest/rdd-programming-guide.html#resilient-distributed-datasets-rdds) (RDD) data structure. This data structure forms the foundation of Apache Spark, but additional data structures on top of the RDD, such as DataFrames, have reduced the need to work directly with RDDs.\n",
    "\n",
    "As of Apache Spark 2.0, the library entered a maintenance mode. This means that MLLib is still available and has not been deprecated, but there will be no new functionality added to the library. Instead, customers are advised to move to the ```org.apache.spark.ml``` library, commonly referred to as Spark ML.\n",
    "\n",
    "**<h2>Spark ML</h2>**\n",
    "\n",
    "\n",
    "Spark ML is the primary library for machine learning development in Apache Spark. It supports DataFrames in its API, versus the classic RDD approach. This makes Spark ML an easier library to work with for data scientists, as Spark DataFrames share many common ideas with the DataFrames used in Pandas and R.\n",
    "\n",
    "The most confusing part about MLLib versus Spark ML is that **they are both the same library**. The difference is that the \"classic\" MLLib namespace is ```org.apache.spark.mllib``` whereas the Spark ML namespace is ```org.apache.spark.ml```. Whenever possible, use the Spark ML namespace when performing new data science activities.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AOYGD4704w4"
   },
   "source": [
    "**<center><h1>Train and validate a model</h1></center>**\n",
    "\n",
    "The process of training and validating a machine learning model using Spark ML is fairly straightforward. The steps are as follows:\n",
    "\n",
    "1. Splitting data.\n",
    "2. Training a model.\n",
    "3. Validating a model.\n",
    "\n",
    "**<h2>Splitting data</h2>**\n",
    "\n",
    "The first step involves splitting data between **training** and **validation** datasets. Doing so allows a data scientist to train a model with a representative portion of the data, while still retaining some percentage as a hold-out dataset. This hold-out dataset can be useful for determining whether the training model is **overfitting** - that is, latching onto the peculiarities of the training dataset rather than finding generally applicable relationships between variables.\n",
    "\n",
    "DataFrames support a ```randomSplit()``` method, which makes this process of splitting data simple.\n",
    "\n",
    "**<h2>Training a model</h2>**\n",
    "\n",
    "Training a model relies on three key abstractions: a **transformer**, an **estimator**, and a **pipeline**.\n",
    "\n",
    "A transformer takes a DataFrame as an input and returns a new DataFrame as an output. Transformers are helpful for performing feature engineering and feature selection, as the result of a transformer is another DataFrame. An example of this might be to read in a text column, map that text column into a set of feature vectors, and output a DataFrame with the newly mapped column. Transformers will implement a ```.transform()``` method.\n",
    "\n",
    "An estimator takes a DataFrame as an input and returns a model. It takes a DataFrame as an input and returns a model, which is itself a transformer. An example of an estimator is the ```LinearRegression``` machine learning algorithm. It accepts a DataFrame and produces a ```Model```. Estimators implement a ```.fit()``` method.\n",
    "\n",
    "Pipelines combine together estimators and transformers and implement a ```.fit()``` method. By breaking out the training process into a series of stages, it's easier to combine multiple algorithms.\n",
    "\n",
    "\n",
    "**<h2>Validating a model</h2>**\n",
    "\n",
    "Once a model has been trained, it becomes possible to validate its results. Spark ML includes built-in summary statistics for models based on the algorithm of choice. Using linear regression for example, the model contains a summary object, which includes scores such as Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and coefficient of determination ($R^2$, pronounced R-squared). These will be the summary measures based on the **training** data.\n",
    "\n",
    "From there, with a **validation** dataset, it is possible to calculate summary statistics on a never-before-seen set of data, running the model's transform() function against the validation dataset. From there, use evaluators such as the RegressionEvaluator to calculate measures such as RMSE, MAE, and $R^2$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exJkxNHb05Kv"
   },
   "source": [
    "**<center><h1>Use other machine learning frameworks</h1></center>**\n",
    "\n",
    "Azure Databricks supports machine learning frameworks other than Spark ML and MLLib. For example, Azure Databricks offers support for popular libraries like TensorFlow and PyTorch.\n",
    "\n",
    "It is possible to install these libraries directly, but the best recommendation is to use the [Databricks Runtime for Machine Learning](https://docs.microsoft.com/en-us/azure/databricks/runtime/mlruntime). This runtime comes with various machine learning libraries pre-installed, including TensorFlow, PyTorch, Keras, and XGBoost. It also includes libraries essential for distributed training, allowing data scientists to take advantage of the distributed nature of Apache Spark.\n",
    "\n",
    "For libraries, which do not support distributed training, it is also possible to use a [single node ](https://docs.microsoft.com/en-us/azure/databricks/clusters/single-node). For example, [PyTorch](https://docs.microsoft.com/en-us/azure/databricks/applications/machine-learning/train-model/pytorch#use-pytorch-on-a-single-node) and [TensorFlow](https://docs.microsoft.com/en-us/azure/databricks/applications/machine-learning/train-model/tensorflow#use-tensorflow-on-a-single-node) both support single node use.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJny5sl05Yf"
   },
   "source": [
    "**<center><h1>Exercise - Train a machine learning model</h1></center>**\n",
    "\n",
    "Now, it's your chance to use Azure Databricks to train a multivariate regression model and interpret its results.\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "- Training a Model.\n",
    "- Validating a Model.\n",
    "\n",
    "**<h2>Instructions</h2>**\n",
    "\n",
    "Follow these instructions to complete the exercise:\n",
    "\n",
    "1. Open the exercise instructions at https://aka.ms/mslearn-dp090.\n",
    "2. Complete the **Training and Validating a Machine Learning Model** exercises.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHPkQune05uW"
   },
   "source": [
    "**<center><h1>Summary</h1></center>**\n",
    "\n",
    "In this module, you learned how to train and evaluate a machine learning model.\n",
    "\n",
    "Now that you've completed this module, you can:\n",
    "\n",
    "- Describe Spark ML.\n",
    "- Train and validate a machine learning model.\n",
    "- Use other machine learning frameworks.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course4_Module4TrainamachinelearningmodelwithAzureDatabricks",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
