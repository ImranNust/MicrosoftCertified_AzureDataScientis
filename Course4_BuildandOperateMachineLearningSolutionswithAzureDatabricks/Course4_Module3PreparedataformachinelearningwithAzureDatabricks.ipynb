{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc_79hyqeW1G"
   },
   "source": [
    "**<center><h1>Introduction</h1></center>**\n",
    "\n",
    "Learn how to prepare data for machine learning in Azure Databricks.\n",
    "\n",
    "\n",
    "**<h2>Learning Objectives</h2>**\n",
    "\n",
    "After completing this module, you’ll be able to:\n",
    "\n",
    "- Describe the concepts of machine learning.\n",
    "- Perform data cleaning.\n",
    "- Perform feature engineering.\n",
    "- Perform data scaling.\n",
    "- Perform data encoding.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqBhKivuvUk"
   },
   "source": [
    "**<center><h1>Understand machine learning concepts</h1></center>**\n",
    "\n",
    "Machine learning is a data science technique used to extract patterns from data allowing computers to identify related data, forecast future outcomes, behaviors, and trends.\n",
    "\n",
    "\n",
    "**<h2>Machine learning as the new programming paradigm</h2>**\n",
    "\n",
    "**<h3>Traditional programming</h3>**\n",
    "\n",
    "In traditional programming, the inputs of hard-coded rules and data are used to arrive at the output of answers.\n",
    "<img src=\"images/02-01-01-traditional-program.png\" />\n",
    "You provide the traditional program with rules and data, and in return, it gives your results or answers.\n",
    "\n",
    "\n",
    "**<h3>Machine learning</h3>**\n",
    "\n",
    "The result of training a machine learning algorithm is that the algorithm has learned the rules to map the input data to answers.\n",
    "\n",
    "<img src=\"images/02-01-01-machine-learning.png\" />\n",
    "\n",
    "In machine learning, you train the algorithm with data and answers, also known as labels, and the algorithm learns the rules to map the data to their respective labels.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AOYGD4704w4"
   },
   "source": [
    "**<center><h1>Perform data cleaning</h1></center>**\n",
    "\n",
    "**Big Data** has become part of the lexicon of organizations worldwide, as more and more organizations look to leverage data to drive more informed business decisions. With this evolution in business decision-making, the amount of raw data collected, along with the number and diversity of data sources, is growing at an astounding rate.\n",
    "\n",
    "Raw data, however, is often noisy and unreliable and may contain missing values and outliers. Using such data for **Machine Learning** can produce misleading results. Thus, data cleaning of the raw data is one of the most important steps in preparing data for Machine Learning. As Machine Learning algorithm learns the rules from data, having clean and consistent data is an important factor in influencing the predictive abilities of the underlying algorithms.\n",
    "\n",
    "The most common type of data available for machine learning is in tabular format. The tabular data is typically available in the form of rows and columns. In tabular data, the row describes a single observation, and each column describes different properties of the observation. Column values can be continuous (numerical), discrete (categorical), datetime (time-series), or text. Columns that are chosen as inputs to the Machine Learning models are also known as model features.\n",
    "\n",
    "Data cleaning deals with issues in the data quality such as errors, missing values and outliers. There are several techniques in dealing with data quality issues and we will discuss some of the common approaches below.\n",
    "\n",
    "\n",
    "**<h2>Imputation of null values</h2>**\n",
    "\n",
    "Null values refer to unknown or missing data as well as irrelevant responses. Strategies for dealing with this scenario include:\n",
    "\n",
    "- Dropping these records: Works when you do not need to use the information for downstream workloads.\n",
    "- Adding a placeholder (for example, -1): Allows you to see missing data later on without violating a schema.\n",
    "- B-asic imputing: Allows you to have a \"best guess\" of what the data could have been, often by using the mean or median of non-missing data for numerical data type, or most_frequent value of non-missing data for categorical data type.\n",
    "- Advanced imputing: Determines the \"best guess\" of what data should be using more advanced strategies such as clustering machine learning algorithms or oversampling techniques such as SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "**<h2>Converting data types</h2>**\n",
    "\n",
    "In some situations, the columns have inconsistent data types. For example, a column can have a combination of numbers presented as strings, like \"44.5\" and \"25.1\". As part of data cleaning you often have to convert the data in the column to its correct data type.\n",
    "\n",
    "\n",
    "**<h2>Duplicate records</h2>**\n",
    "\n",
    "In some situations, you find duplicate records in the table. The easiest solution is to drop the duplicate records.\n",
    "\n",
    "**<h2>Outliers</h2>**\n",
    "\n",
    "\n",
    "An outlier is defined as an observation that is significantly different to all other observations in a given column. There are several ways to identify outliers, and one common approach is to compute the Z-score for an observation x.\n",
    "\n",
    "You can use similar strategies as imputing null values to deal with outliers. However, it is important to note that outliers are not necessarily invalid data and, in some situations, it is perfectly valid to retain the outliers in your training data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJny5sl05Yf"
   },
   "source": [
    "**<center><h1>Perform feature engineering</h1></center>**\n",
    "\n",
    "Machine learning models are as strong as the data they are trained on. Often it is important to derive features from existing raw data that better represent the nature of the data and thus help improve the predictive power of the machine learning algorithms. This process of generating new predictive features from existing raw data is commonly referred to as **feature engineering**.\n",
    "\n",
    "**<h2>Feature engineering</h2>**\n",
    "\n",
    "There are many valid approaches to feature engineering and some of the most popular ones, categorized by data type, are as follows:\n",
    "\n",
    "- Aggregation (count, sum, average, mean, median, and the like)\n",
    "Part-of (year of date, month of date, week of date, and the like)\n",
    "- Binning (grouping entities into bins and then applying aggregations)\n",
    "- Flagging (boolean conditions resulting in True of False)\n",
    "- Frequency-based (calculating the frequencies of the levels of one or more categorical variables)\n",
    "- Embedding (transforming one or more categorical or text features into a new set of features, possibly with a different cardinality)\n",
    "- Deriving by example\n",
    "\n",
    "Feature engineering is not limited to the above list and can involve domain knowledge-based approaches for deriving features.\n",
    "\n",
    "Let’s work with an example to understand the process of feature engineering. In our example, we are working with a system that gives us weather data on an hourly basis, and we have a column in the data that is hour of day. The ```hour of day``` column is of type integer and it can assume any integer value in the range ```[0, 23]```.\n",
    "\n",
    "The question is, how best to represent this data to a machine learning algorithm that can learn its cyclical nature? One approach is to engineer a set of new features that transforms the ```hour of day``` column using sine and cosine functions. These derived features are plotted in the figure below for the range ```[0, 24]```:\n",
    "\n",
    "\n",
    "<img src=\"images/02-01-03-engineered-features.jpg\" />\n",
    "\n",
    "The cosine function provides symmetrically equal weights to corresponding AM and PM hours, and the sine function provides symmetrically opposite weights to corresponding AM and PM hours. Both functions capture the cyclical nature of ```hour of day```.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHPkQune05uW"
   },
   "source": [
    "**<center><h1>Perform data scaling</h1></center>**\n",
    "\n",
    "Scaling numerical features is an important part of preprocessing data for machine learning. Typically the range of values each input feature takes vary greatly between features. There are many machine learning algorithms that are sensitive to the magnitude of the input features and thus without feature scaling, higher weights might get assigned to features with higher magnitudes irrespective of the importance of the feature on the predicted output.\n",
    "\n",
    "There are two common approaches to scaling numerical features:\n",
    "\n",
    "- **Normalization**\n",
    "- **Standardization**\n",
    "\n",
    "We will discuss each of these approaches below.\n",
    "\n",
    "\n",
    "**<h2>Normalization</h2>**\n",
    "\n",
    "Normalization mathematically rescales the data into the range [0, 1].\n",
    "\n",
    "For example, for each individual value, you can subtract the minimum value for that input in the training dataset, and then divide by the range of the values in the training dataset. The range of the values is the difference between the maximum value and the minimum value.\n",
    "\n",
    "\n",
    "**<h2>Standardization</h2>**\n",
    "\n",
    "Standardization rescales the data to have mean = 0 and standard deviation = 1.\n",
    "\n",
    "For the numeric input, you first compute the mean and standard deviation using all the data available in the training dataset. Then, for each individual input value, you scale that value by subtracting the mean and then dividing by the standard deviation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST2wRWOM056H"
   },
   "source": [
    "**<center><h1>Perform data encoding</h1></center>**\n",
    "\n",
    "A common type of data that is prevalent in machine learning is called categorical data. Categorical data implies discrete or a limited set of values. For example, a person’s gender or ethnicity is considered as categorical. Let’s consider the following data table:\n",
    "\n",
    "<img src=\"images/image1.png\" />\n",
    "\n",
    "In the table above, the row describes a single observation, and each column describes different properties of the observation. In the table, we have two types of data, numeric data such as Quantity and Price, and categorical data such as Make and Color. In the previous lesson, we looked at examples of how to scale numeric data types. Furthermore, it is important to note that in machine learning, we ultimately always work with numbers or specifically, vectors. In this context, a vector is either an array of numbers, or nested arrays of numbers. So how does one encode categorical data for the purposes of machine learning? We will look at two common approaches for **encoding** categorical data:\n",
    "\n",
    "- Ordinal encoding\n",
    "- One-hot encoding\n",
    "\n",
    "**<h2>Ordinal encoding</h2>**\n",
    "\n",
    "Ordinal encoding, converts categorical data into integer codes ranging from 0 to (number of categories – 1). For example, the categories Make and Color from the above table are encoded as:\n",
    "\n",
    "\n",
    "<img src=\"images/image2.png\" />\n",
    "\n",
    "Using the above encoding, the transformed table is shown below:\n",
    "\n",
    "\n",
    "<img src=\"images/image3.png\" />\n",
    "\n",
    "**<h2>One-hot encoding</h2>**\n",
    "\n",
    "One-hot encoding is often the recommended approach, and it involves transforming each categorical value into n (= number of categories) binary values, with one of them 1, and all others 0. For example, the above table can be transformed as:\n",
    "\n",
    "\n",
    "<img src=\"images/image4.png\" />\n",
    "\n",
    "One-hot encoding is often preferred over ordinal encoding because it encodes each category item with equal weight. In our above example, the ordinal encoder assigned color ```Green = 1``` and color ```Blue = 2```, and that can imply that color Blue is twice as important as color Green. Whereas, with one-hot encoding each color is weighted equally.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SThUT0Ru06DO"
   },
   "source": [
    "**<center><h1>Exercise - Prepare data for machine learning</h1></center>**\n",
    "\n",
    "Now, it's your chance to use Azure Databricks to prepare data for Machine Learning.\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "- Handling missing data.\n",
    "- Feature Engineering.\n",
    "- Scaling Numeric features.\n",
    "- Encoding Categorical Features.\n",
    "\n",
    "**<h2>Instructions</h2>**\n",
    "\n",
    "Follow these instructions to complete the exercise:\n",
    "\n",
    "1. Open the exercise instructions at https://aka.ms/mslearn-dp090.\n",
    "2. Complete the **Preparing Data for Machine Learning** exercises.\n",
    "\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeGvZX7806kP"
   },
   "source": [
    "**<center><h1>Summary</h1></center>**\n",
    "\n",
    "\n",
    "In this module, you learned how to prepare data for machine learning in Azure Databricks.\n",
    "\n",
    "Now that you've completed this module, you can:\n",
    "\n",
    "- Describe the concepts of machine learning.\n",
    "- Perform data cleaning.\n",
    "- Perform feature engineering.\n",
    "- Perform data scaling.\n",
    "- Perform data encoding.\n",
    "\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course4_Module3PreparedataformachinelearningwithAzureDatabricks",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
