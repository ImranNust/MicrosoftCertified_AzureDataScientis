{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zojk54xfVCdn"
   },
   "source": [
    "**<center><h1>Introduction</h1></center>**\n",
    "\n",
    "Classification is a form of machine learning that is used to predict which category, or class, an item belongs to. For example, a health clinic might use the characteristics of a patient (such as age, weight, blood pressure, and so on) to predict whether the patient is at risk of diabetes. In this case, the characteristics of the patient are the features, and the label is a classification of either 0 or 1, representing non-diabetic or diabetic.\n",
    "\n",
    "<img src = \"images/diabetes.png\" />\n",
    "\n",
    "Classification is an example of a supervised machine learning technique in which you train a model using data that includes both the features and known values for the label, so that the model learns to fit the feature combinations to the label. Then, after training has been completed, you can use the trained model to predict labels for new items for which the label is unknown.\n",
    "\n",
    "You can use Microsoft Azure Machine Learning designer to create classification models by using a drag and drop visual interface, without needing to write any code.\n",
    "\n",
    "In this module, you'll learn how to:\n",
    "\n",
    "Use Azure Machine Learning designer to train a classification model.\n",
    "Use a classification model for inferencing.\n",
    "Deploy a classification model as a service.\n",
    "To complete this module, you'll need a Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at https://azure.microsoft.com.\n",
    "\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHs526pEVcWt"
   },
   "source": [
    "**<center><h1>Create an Azure Machine Learning workspace</h1></center>**\n",
    "\n",
    "Azure Machine Learning is a cloud-based platform for building and operating machine learning solutions in Azure. It includes a wide range of features and capabilities that help data scientists prepare data, train models, publish predictive services, and monitor their usage. One of these features is a visual interface called designer, that you can use to train, test, and deploy machine learning models without writing any code.\n",
    "\n",
    "**<h2>Create an Azure Machine Learning workspace</h2>**\n",
    "\n",
    "To use Azure Machine Learning, you create a workspace in your Azure subscription. You can then use this workspace to manage data, compute resources, code, models, and other artifacts related to your machine learning workloads.\n",
    "\n",
    "<mark>Note: This module is one of many that make use of an Azure Machine Learning workspace, including the other modules in the [Create no-code predictive models with Azure Machine Learning](https://docs.microsoft.com/en-us/learn/paths/create-no-code-predictive-models-azure-machine-learning/) learning path. If you are using your own Azure subscription, you may consider creating the workspace once and reusing it in other modules. Your Azure subscription will be charged a small amount for data storage as long as the Azure Machine Learning workspace exists in your subscription, so we recommend you delete the Azure Machine Learning workspace when it is no longer required.</mark>\n",
    "\n",
    "If you do not already have one, follow these steps to create a workspace:\n",
    "\n",
    "1. [Sign into the Azure portal](https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize?redirect_uri=https%3A%2F%2Fportal.azure.com%2Fsignin%2Findex%2F&response_type=code%20id_token&scope=https%3A%2F%2Fmanagement.core.windows.net%2F%2Fuser_impersonation%20openid%20email%20profile&state=OpenIdConnect.AuthenticationProperties%3Dz72cT56dMDrMEzqmMXYwoKHwBE4ZVsku4nlPA6bVjj1vgK4Oq5qCoRKDFgRcmtnFolsmn6UV8SNtBPQvKbkrWLEG304KFtgu-Z0jKaiwGkfc1PYxCP2qhpuEEXT1NcNrpsSQMn4-4mjHmBPLT8tRBLuMoCDLN-g2AQOxEvgaJc8MPMwktp3SyMPGYiKu362EKXfFFzapaCtBuQsJOSp5DB3a1ulLu4Fn8mcnEMspnCD-z93f1IbSeMXqcPdnXov7_hs6Blp4Vhwmcqi-ZZywmJty4Qi2hUirVWCQR_VtX7oVCbF6iUZ4SqvxG33s8G4ll0ps6zesFWjb4i48k6wFv7hA9hv4llbUveq7KfTtnoz9ZbnqlIHKEH7t_k19CX4Qro0o8B2cWtDao0qjAKlsfA&response_mode=form_post&nonce=637836117167542965.N2NmODIwYTctNWZjMi00Nzk5LWE0ZjctZDFmNTI4ZGM2YzllZGZhYWMzNTUtYWU2OC00MzM4LTk4YzctM2MwMThjNDU3Mzg3&client_id=c44b4083-3bb0-49c1-b47d-974e53cbdf3c&site_id=501430&client-request-id=c9029c42-b8ae-4c34-894e-f5087e777224&x-client-SKU=ID_NET472&x-client-ver=6.12.2.0) using your Microsoft credentials.\n",
    "2. Select ï¼‹ **Create a resource**, search for **Machine Learning**, and create a new Machine Learning resource the following settings:\n",
    "- **Subscription:** Your Azure subscription\n",
    "- **Resource group:** Create or select a resource group\n",
    "- **Workspace name:** Enter a unique name for your workspace\n",
    "- **Region:** Select the geographical region closest to you\n",
    "- **Storage account:** Note the default new storage account that will be created for your workspace\n",
    "- **Key vault:** Note the default new key vault that will be created for your workspace\n",
    "- **Application insights:** Note the default new application insights resource that will be created for your workspace\n",
    "- **Container registry:** None (one will be created automatically the first time you deploy a model to a container)\n",
    "\n",
    "3. Wait for your workspace to be created (it can take a few minutes). Then go to it in the portal.\n",
    "4. On the **Overview** page for your workspace, launch Azure Machine Learning Studio (or open a new browser tab and navigate to https://ml.azure.com), and sign into Azure Machine Learning studio using your Microsoft account.\n",
    "In Azure Machine Learning studio, toggle the â˜° icon at the top left to view the various pages in the interface. You can use these pages to manage the resources in your workspace.\n",
    "\n",
    "You can manage your workspace using the Azure portal, but for data scientists and Machine Learning operations engineers, Azure Machine Learning studio provides a more focused user interface for managing workspace resources.\n",
    "\n",
    "<hr></hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q03izlZWhuh"
   },
   "source": [
    "**<center><h1>Create compute resources</h1></center>**\n",
    "\n",
    "To train and deploy models using Azure Machine Learning designer, you need compute targets to run the training process. You will also use these compute targets to test the trained model after its deployment.\n",
    "\n",
    "**<h2>Create compute targets</h2>**\n",
    "\n",
    "Compute targets are cloud-based resources on which you can run model training and data exploration processes.\n",
    "\n",
    "In [Azure Machine Learning studio](https://ml.azure.com/), view the **Compute** page (under **Manage**). You manage the compute targets for your data science activities in the studio. There are four kinds of compute resource that you can create:\n",
    "\n",
    "- **Compute Instances:** Development workstations that data scientists can use to work with data and models.\n",
    "- **Compute Clusters:** Scalable clusters of virtual machines for on-demand processing of experiment code.\n",
    "- **Inference Clusters:** Deployment targets for predictive services that use your trained models.\n",
    "- **Attached Compute:** Links to existing Azure compute resources, such as Virtual Machines or Azure Databricks clusters.\n",
    "\n",
    "<mark>Note: Compute instances and clusters are based on standard Azure virtual machine images. For this module, the Standard_DS11_v2 image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.</mark>\n",
    "\n",
    "1. On the **Compute Instances** tab, add a new compute instance with the following settings:\n",
    "\n",
    "  - **Compute name:** enter a unique name\n",
    "  - **Virtual Machine type:** CPU\n",
    "  - **Virtual Machine size:**\n",
    "    - Choose **Select from all options**\n",
    "    - Search for and select **Standard_DS11_v2**\n",
    "2. While the compute instance is being created, switch to the **Compute Clusters** tab, and add a new compute cluster with the following settings:\n",
    "\n",
    "- **Location:** Select the same as your workspace. If that location is not listed, choose the one closest to you\n",
    "- **Virtual Machine tier:** Dedicated\n",
    "- **Virtual Machine type:** CPU\n",
    "- **Virtual Machine size:**\n",
    "  - Choose **Select from all options**\n",
    "  - Search for and select **Standard_DS11_v2**\n",
    "- **Compute name:** enter a unique name\n",
    "- **Minimum number of nodes:** 0\n",
    "- **Maximum number of nodes:** 2\n",
    "- **Idle seconds before scale down:** 120\n",
    "- **Enable SSH access:** Unselected\n",
    "\n",
    "<mark>Tip: After you finish the entire module, be sure to follow the Clean Up instructions at the end of the module to stop your compute resources. Stop your compute resources to ensure your subscription won't be charged.</mark>\n",
    "\n",
    "The compute targets take some time to be created. You can move onto the next unit while you wait.\n",
    "\n",
    "<hr></hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hELsKneMYgkL"
   },
   "source": [
    "**<center><h1>Explore data</h1></center>**\n",
    "\n",
    "To train a classification model, you need a dataset that includes historical features (characteristics of the entity for which you want to make a prediction) and known label values (the class indicator that you want to train a model to predict)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1YE6DFQYlIq"
   },
   "source": [
    "**<h2>Create a dataset</h2>**\n",
    "\n",
    "In Azure Machine Learning, data for model training and other operations is usually encapsulated in an object called a dataset.\n",
    "\n",
    "1. In [Azure Machine Learning studio](https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize?client_id=d7304df8-741f-47d3-9bc2-df0e24e2071f&scope=https%3A%2F%2Fmanagement.core.windows.net%2F%2F.default%20openid%20profile%20offline_access&redirect_uri=https%3A%2F%2Fml.azure.com&client-request-id=bcae5ad4-7135-473d-97ec-675793fda9f9&response_mode=fragment&response_type=code&x-client-SKU=msal.js.browser&x-client-VER=2.13.1&x-client-OS=&x-client-CPU=&client_info=1&code_challenge=ipKkhzqwGl1ngZTkHit9lInwWndStZ6Zg_39oE7jc8Y&code_challenge_method=S256&nonce=19bda47c-c0c7-4ba4-aca0-42972300e69b&state=eyJpZCI6IjRhY2NiYTdhLTM4YWUtNDZiYy05M2VjLTA0ZmQ0OWY4OGZjMSIsIm1ldGEiOnsiaW50ZXJhY3Rpb25UeXBlIjoicmVkaXJlY3QifX0%3D), view the **Datasets** page. Datasets represent specific data files or tables that you plan to work with in Azure ML.\n",
    "\n",
    "2. Create a dataset **from web files**, using the following settings:\n",
    "\n",
    "- **Basic Info:**\n",
    "  - **Web URL:** https://aka.ms/diabetes-data\n",
    "  - **Name:** diabetes-data\n",
    "  - **Dataset type:** Tabular\n",
    "  - **Description:** Diabetes data\n",
    "  - **Skip data validation:** Do not select\n",
    "- **Settings and preview:**\n",
    "  - **File format:** Delimited\n",
    "  - **Delimiter:** Comma\n",
    "  - **Encoding:** UTF-8\n",
    "  - **Column headers:** Only first file has headers\n",
    "  - **Skip rows:** None\n",
    "- **Schema:**\n",
    "  - Include all columns other than **Path**\n",
    "  - Review the automatically detected types\n",
    "- **Confirm details:**\n",
    "  - Do not profile the dataset after creation\n",
    "\n",
    "3. After the dataset has been created, open it and view the **Explore** page to see a sample of the data. This data represents details from patients who have been tested for diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtLzj19iYrSv"
   },
   "source": [
    "**<h2>Create a pipeline</h2>**\n",
    "\n",
    "\n",
    "To get started with Azure Machine Learning designer, first you must create a pipeline and add the dataset you want to work with.\n",
    "\n",
    "1. In [Azure Machine Learning studio](https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize?client_id=d7304df8-741f-47d3-9bc2-df0e24e2071f&scope=https%3A%2F%2Fmanagement.core.windows.net%2F%2F.default%20openid%20profile%20offline_access&redirect_uri=https%3A%2F%2Fml.azure.com&client-request-id=bcae5ad4-7135-473d-97ec-675793fda9f9&response_mode=fragment&response_type=code&x-client-SKU=msal.js.browser&x-client-VER=2.13.1&x-client-OS=&x-client-CPU=&client_info=1&code_challenge=ipKkhzqwGl1ngZTkHit9lInwWndStZ6Zg_39oE7jc8Y&code_challenge_method=S256&nonce=19bda47c-c0c7-4ba4-aca0-42972300e69b&state=eyJpZCI6IjRhY2NiYTdhLTM4YWUtNDZiYy05M2VjLTA0ZmQ0OWY4OGZjMSIsIm1ldGEiOnsiaW50ZXJhY3Rpb25UeXBlIjoicmVkaXJlY3QifX0%3D) for your workspace, view the **Designer** page and select + to create a new pipeline.\n",
    "2. At the top left-hand side of the screen, click on the default pipeline name **(Pipeline-Created-on-date)** and change it to **Diabetes Training**.\n",
    "3. You need to specify a compute target on which to run the pipeline. In the **Settings** pane, click on **Select compute target** to select the compute cluster you created previously (if the **Settings** pane is not visible, select the **âš™** icon next to the pipeline name at the top).\n",
    "4. Next to the pipeline name on the left, select the button >> to expand the panel. Drag the **diabetes-data** dataset you created in the previous exercise onto the canvas.\n",
    "5. Right-click (Ctrl+click on a Mac) the **diabetes-data** dataset on the canvas, and on the **Outputs** menu, select **Dataset output** by clicking on the Preview data graph icon.\n",
    "6. Review the schema of the data, noting that you can see the distributions of the various columns as histograms.\n",
    "7. Scroll to the right and select the column heading for the **Diabetic** column, and note that it contains two values **0** and **1**. These values represent the two possible classes for the label that your model will predict, with a value of **0** meaning that the patient does not have diabetes, and a value of **1** meaning that the patient is diabetic.\n",
    "8. Scroll back to the left and review the other columns, which represent the features that will be used to predict the label. Note that most of these columns are numeric, but each feature is on its own scale. For example, **Age** values range from 21 to 77, while **DiabetesPedigree** values range from 0.078 to 2.3016. When training a machine learning model, it is sometimes possible for larger values to dominate the resulting predictive function, reducing the influence of features that on a smaller scale. Typically, data scientists mitigate this possible bias by normalizing the numeric columns so they're on the similar scales.\n",
    "9. Close the **diabetes-data result visualization** window so that you can see the dataset on the canvas like this:\n",
    "\n",
    "<img src=\"images/diabetes-data.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTN40lEcYu1W"
   },
   "source": [
    "**<h2>Add Transformations</h2>**\n",
    "\n",
    "Before you can train a model, you typically need to apply some preprocessing transformations to the data.\n",
    "\n",
    "1. In the pane on the left, expand the **Data Transformation** section, which contains a wide range of modules you can use to transform data before model training.\n",
    "2. Drag a **Normalize Data** module to the canvas, below the **diabetes-data** dataset. Then connect the output from the bottom of the **diabetes-data** dataset to the input at the top of the **Normalize Data** module, like this:\n",
    "\n",
    "<img src=\"images/dataset-normalize.png\"  />\n",
    "\n",
    "3. Select the **Normalize Data** module and view its settings, noting that it requires you to specify the transformation method and the columns to be transformed.\n",
    "4. Set the transformation to **MinMax** and edit the columns to include the following columns by name, as shown in the image:\n",
    "- **Pregnancies**\n",
    "- **PlasmaGlucose**\n",
    "- **DiastolicBloodPressure**\n",
    "- **TricepsThickness**\n",
    "- **SerumInsulin**\n",
    "- **BMI**\n",
    "- **DiabetesPedigree**\n",
    "- **Age**\n",
    "\n",
    "<img src=\"images/normalize-data.png\" />\n",
    "\n",
    "The data transformation is normalizing the numeric columns to put them on the same scale, which should help prevent columns with large values from dominating model training. You'd usually apply a whole bunch of pre-processing transformations like this to prepare your data for training, but we'll keep things simple in this exercise.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lwHJPWBY1m4"
   },
   "source": [
    "**<h2>Run the pipeline</h2>**\n",
    "\n",
    "\n",
    "To apply your data transformations, you need to run the pipeline as an experiment.\n",
    "\n",
    "1. Ensure your pipeline looks similar to this:\n",
    "\n",
    "<img src=\"images/data-prep-pipeline.png\"  />\n",
    "\n",
    "2. Select **Submit**, and run the pipeline as a new experiment named **mslearn-diabetes-training** on your compute cluster.\n",
    "3. Wait for the run to finish - this may take a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXOg1U9VY6YK"
   },
   "source": [
    "**<h2>View the transformed data</h2>**\n",
    "\n",
    "The dataset is now prepared for model training.\n",
    "\n",
    "1. Select the completed **Normalize Data** module, and in its **Settings** pane on the right, on the **Outputs + logs** tab, select the Visualize icon for the **Transformed dataset**.\n",
    "2. View the data, noting that the numeric columns you selected have been normalized to a common scale.\n",
    "3. Close the normalized data result visualization.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omBgDOkzc01a"
   },
   "source": [
    "**<center><h1>Create and run a training pipeline</h1></center>**\n",
    "\n",
    "After you've used data transformations to prepare the data, you can use it to train a machine learning model.\n",
    "\n",
    "**<h2>Add training modules</h2>**\n",
    "\n",
    "It's common practice to train the model using a subset of the data, while holding back some data with which to test the trained model. This enables you to compare the labels that the model predicts with the actual known labels in the original dataset.\n",
    "\n",
    "In this exercise, you're going to work through steps to extend the **Diabetes Training** pipeline as shown here:\n",
    "\n",
    "<img src=\"images/train-score-pipeline.png\"  />\n",
    "\n",
    "Follow the steps below, using the image above for reference as you add and configure the required modules.\n",
    "\n",
    "1. Open the **Diabetes Training** pipeline you created in the previous unit if it's not already open.\n",
    "2. In the pane on the left, in the **Data Transformations** section, drag a **Split Data** module onto the canvas under the **Normalize Data** module. Then connect the Transformed Dataset (left) output of the **Normalize Data** module to the input of the **Split Data** module.\n",
    "3. Select the **Split Data** module, and configure its settings as follows:\n",
    "  - **Splitting mode** Split Rows\n",
    "  - **Fraction of rows in the first output dataset:** 0.7\n",
    "  - **Random seed:** 123\n",
    "  - **Stratified split:** False\n",
    "4. Expand the **Model Training** section in the pane on the left, and drag a **Train Model** module to the canvas, under the **Split Data** module. Then connect the Result dataset1 (left) output of the **Split Data** module to the Dataset (right) input of the **Train Model** module.\n",
    "5. The model we're training will predict the **Diabetic** value, so select the **Train Model** module and modify its settings to set the **Label column** to **Diabetic** (matching the case and spelling exactly!)\n",
    "6. The **Diabetic** label the model will predict is a class (0 or 1), so we need to train the model using a classification algorithm. Specifically, there are two possible classes, so we need a binary classification algorithm. Expand the **Machine Learning Algorithms** section, and under **Classification**, drag a **Two-Class Logistic Regression** module to the canvas, to the left of the **Split Data** module and above the Train Model module. Then connect its output to the **Untrained model** (left) input of the **Train Model** module.\n",
    "\n",
    "<mark>Note: There are multiple algorithms you can use to train a classification model. For help choosing one, take a look at the Machine Learning Algorithm Cheat Sheet for Azure Machine Learning designer.</mark>\n",
    "\n",
    "7. To test the trained model, we need to use it to score the validation dataset we held back when we split the original data - in other words, predict labels for the features in the validation dataset. Expand the **Model Scoring & Evaluation** section and drag a **Score Model** module to the canvas, below the **Train Model** module. Then connect the output of the **Train Model** module to the **Trained model** (left) input of the **Score Model** module; and connect the **Results dataset2** (right) output of the Split Data module to the **Dataset** (right) input of the **Score Model** module.\n",
    "8. Ensure your pipeline looks like this:\n",
    "\n",
    "\n",
    "<img src=\"images/train-score-pipeline.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkDcCRfGdF_r"
   },
   "source": [
    "**<h2>Run the training pipeline</h2>**\n",
    "\n",
    "Now you're ready to run the training pipeline and train the model.\n",
    "\n",
    "1. Select **Submit**, and run the pipeline using the existing experiment named mslearn-diabetes-training.\n",
    "2. Wait for the experiment run to finish. This may take 5 minutes or more.\n",
    "3. When the experiment run has finished, select the **Score Model** module and in the settings pane, on the **Outputs + Logs** tab, under **Data outputs** in the **Scored dataset** section, use the **Preview data** icon to view the results.\n",
    "4. Scroll to the right, and note that next to the **Diabetic** column (which contains the known true values of the label) there is a new column named **Scored Labels**, which contains the predicted label values, and a **Scored Probabilities** columns containing a probability value between 0 and 1. This indicates the probability of a positive prediction, so probabilities greater than 0.5 result in a predicted label of 1 (diabetic), while probabilities between 0 and 0.5 result in a predicted label of 0 (not diabetic).\n",
    "5. Close the **Score Model** result visualization window.\n",
    "\n",
    "The model is predicting values for the **Diabetic** label, but how reliable are its predictions? To assess that, you need to evaluate the model.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVf6qG8MfUPi"
   },
   "source": [
    "**<center><h1>Evaluate a classification model\n",
    "Completed</h1></center>**\n",
    "\n",
    "\n",
    "\n",
    "The validation data you held back and used to score the model includes the known values for the label. So to validate the model, you can compare the true values for the label to the label values that were predicted when you scored the validation dataset. Based on this comparison, you can calculate various metrics that describe how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcQUO0Zqfe8J"
   },
   "source": [
    "**<h2>Add an Evaluate Model module</h2>**\n",
    "\n",
    "1. Open the **Diabetes Training** pipeline you created in the previous unit if it's not already open.\n",
    "2. In the pane on the left, in the **Model Scoring & Evaluation** section, drag an **Evaluate Model** module to the canvas, under the **Score Model** module, and connect the output of the **Score Model** module to the **Scored dataset** (left) input of the **Evaluate Model** module.\n",
    "3. Ensure your pipeline looks like this:\n",
    "\n",
    "<img src=\"images/evaluate-pipeline.png\"  />\n",
    "\n",
    "4. Select **Submit**, and run the pipeline using the existing experiment named **mslearn-diabetes-training**.\n",
    "5. Wait for the experiment run to finish.\n",
    "6. When the experiment run has finished, select the **Evaluate Model** module and in the settings pane, on the **Outputs + Logs** tab, under **Data outputs** in the **Evaluation results** section, use the **Preview Data** icon to view the performance metrics. These metrics can help data scientists assess how well the model predicts based on the validation data.\n",
    "7. View the confusion matrix for the model, which is a tabulation of the predicted and actual value counts for each possible class. For a binary classification model like this one, where you're predicting one of two possible values, the confusion matrix is a 2x2 grid showing the predicted and actual value counts for classes 0 and 1, similar to this:\n",
    "\n",
    "<img src=\"images/confusion-matrix.png\"  />\n",
    "\n",
    "The confusion matrix shows cases where both the predicted and actual values were 1 (known as true positives) at the top left, and cases where both the predicted and the actual values were 0 (true negatives) at the bottom right. The other cells show cases where the predicted and actual values differ (false positives and false negatives). The cells in the matrix are colored so that the more cases represented in the cell, the more intense the color - with the result that you can identify a model that predicts accurately for all classes by looking for a diagonal line of intensely colored cells from the top left to the bottom right (in other words, the cells where the predicted values match the actual values). For a multi-class classification model (where there are more than two possible classes), the same approach is used to tabulate each possible combination of actual and predicted value counts - so a model with three possible classes would result in a 3x3 matrix with a diagonal line of cells where the predicted and actual labels match.\n",
    "\n",
    "8. Review the metrics to the left of the confusion matrix, which include:\n",
    "\n",
    " - **Accuracy:** The ratio of correct predictions (true positives + true negatives) to the total number of  predictions. In other words, what proportion of diabetes predictions did the model get right?\n",
    " - **Precision:** The fraction of positive cases correctly identified (the number of true positives divided by the number of true positives plus false positives). In other words, out of all the patients that the model predicted as having diabetes, how many are actually diabetic?\n",
    " - **Recall:** The fraction of the cases classified as positive that are actually positive (the number of true positives divided by the number of true positives plus false negatives). In other words, out of all the patients who actually have diabetes, how many did the model identify?\n",
    " - **F1 Score:** An overall metric that essentially combines precision and recall.\n",
    " - We'll return to **AUC** later.\n",
    "\n",
    "Of these metric, accuracy is the most intuitive. However, you need to be careful about using simple accuracy as a measurement of how well a model works. Suppose that only 3% of the population is diabetic. You could create a model that always predicts 0 and it would be 97% accurate - just not very useful! For this reason, most data scientists use other metrics like precision and recall to assess classification model performance.\n",
    "\n",
    "9. Above the list of metrics, note that there's a **Threshold** slider. Remember that what a classification model predicts is the probability for each possible class. In the case of this binary classification model, the predicted probability for a positive (that is, diabetic) prediction is a value between 0 and 1. By default, a predicted probability for diabetes including or above 0.5 results in a class prediction of 1, while a prediction below this threshold means that there's a greater probability of the patient not having diabetes (remember that the probabilities for all classes add up to 1), so the predicted class would be 0. Try moving the threshold slider and observe the effect on the confusion matrix. If you move it all the way to the left (0), the Recall metric becomes 1, and if you move it all the way to the right (1), the Recall metric becomes 0.\n",
    "\n",
    "10. Look above the Threshold slider at the **ROC curve** (ROC stands for receiver operating characteristic, but most data scientists just call it a ROC curve). Another term for recall is **True positive rate**, and it has a corresponding metric named **False positive rate**, which measures the number of negative cases incorrectly identified as positive compared the number of actual negative cases. Plotting these metrics against each other for every possible threshold value between 0 and 1 results in a curve. In an ideal model, the curve would go all the way up the left side and across the top, so that it covers the full area of the chart. The larger the area under the curve (which can be any value from 0 to 1), the better the model is performing - this is the **AUC** metric listed with the other metrics below. To get an idea of how this area represents the performance of the model, imagine a straight diagonal line from the bottom left to the top right of the ROC chart. This represents the expected performance if you just guessed or flipped a coin for each patient - you could expect to get around half of them right, and half of them wrong, so the area under the diagonal line represents an AUC of 0.5. If the AUC for your model is higher than this for a binary classification model, then the model performs better than a random guess.\n",
    "\n",
    "11. Close the **Evaluate Model result visualization** window.\n",
    "\n",
    "The performance of this model isn't all that great, partly because we performed only minimal feature engineering and pre-processing. You could try a different classification algorithm, such as **Two-Class Decision Forest**, and compare the results. You can connect the outputs of the **Split Data** module to multiple **Train Model** and **Score Model** modules, and you can connect a second **Score Model** module to the **Evaluate Model** module to see a side-by-side comparison. The point of the exercise is simply to introduce you to classification and the Azure Machine Learning designer interface, not to train a perfect model!\n",
    "\n",
    "<hr></hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEURJ9JRhK5c"
   },
   "source": [
    "**<center><h1>Create an inference pipeline</h1></center>**\n",
    "\n",
    "After creating and running a pipeline to train the model, you need a second pipeline that performs the same data transformations for new data, and then uses the trained model to infer (in other words, predict) label values based on its features. This pipeline will form the basis for a predictive service that you can publish for applications to use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-s2V9MkhYZQ"
   },
   "source": [
    "**<h2>Create an inference pipeline</h2>**\n",
    "\n",
    "1. In Azure Machine Learning Studio, click the **Designer** page to view all of the pipelines you have created. Then open the **Diabetes Training** pipeline you created previously.\n",
    "\n",
    "2. Navigate to the the **Create inference pipeline** drop-down list, located on the top right hand corner of the screen. If you do not see it, you may need to expand your screen or click on the ... three dots which represent **More Actions** on the top right hand corner. Then click **Real-time inference pipeline**. After a few seconds, a new version of your pipeline named **Diabetes Training-real time inference** will be opened.\n",
    "\n",
    "If the pipeline does not include **Web Service Input** and **Web Service Output** modules, go back to the **Designer** page and then re-open the **Diabetes Training-real time inference **pipeline.\n",
    "\n",
    "3. Rename the new pipeline to **Predict Diabetes**, and then review the new pipeline. It contains a web service input for new data to be submitted, and a web service output to return results. Some of the transformations and training steps have been encapsulated in this pipeline so that the statistics from your training data will be used to normalize any new data values, and the trained model will be used to score the new data.\n",
    "\n",
    "You are going to make the following changes to the inference pipeline:\n",
    "\n",
    "<img src=\"images/inference-changes.png\"  />\n",
    "\n",
    "- Replace the **diabetes-data** dataset with an **Enter Data Manually** module that does not include the label column (**Diabetic**).\n",
    "\n",
    "- Remove the **Evaluate Model** module.\n",
    "\n",
    "- Insert an **Execute Python Script** module before the web service output to return only the patient ID, predicted label value, and probability.\n",
    "\n",
    " Follow the remaining steps below, using the image and information above for reference as you modify the pipeline.\n",
    "\n",
    "4. The inference pipeline assumes that new data will match the schema of the original training data, so the **diabetes-data** dataset from the training pipeline is included. However, this input data includes the **Diabetic** label that the model predicts, which is unintuitive to include in new patient data for which a diabetes prediction has not yet been made. Delete this module and replace it with an Enter **Data Manually** module from the **Data Input and Output** section, containing the following CSV data, which includes feature values without labels for three new patient observations:\n",
    "\n",
    "```\n",
    "PatientID,Pregnancies,PlasmaGlucose,DiastolicBloodPressure,TricepsThickness,SerumInsulin,BMI,DiabetesPedigree,Age\n",
    "1882185,9,104,51,7,24,27.36983156,1.350472047,43\n",
    "1662484,6,73,61,35,24,18.74367404,1.074147566,75\n",
    "1228510,4,115,50,29,243,34.69215364,0.741159926,59\n",
    "```\n",
    "\n",
    "5. Connect the new **Enter Data Manually** module to the same **Dataset** input of the **Apply Transformation** module as the **Web Service Input**.\n",
    "\n",
    "6. The inference pipeline includes the **Evaluate Model** module, which is not useful when predicting from new data, so delete this module.\n",
    "\n",
    "7. The output from the **Score Model** module includes all of the input features as well as the predicted label and probability score. To limit the output to only the prediction and probability:\n",
    "\n",
    "  - Delete the connection between the **Score Model** module and the **Web Service Output**.\n",
    "\n",
    "  - Add an **Execute Python Script** module from the **Python Language** section, replacing all of the default python script with the following code (which selects only the **PatientID, Scored Labels** and **Scored Probabilities** columns and renames them appropriately):\n",
    "  ```\n",
    "  import pandas as pd\n",
    "\n",
    "def azureml_main(dataframe1 = None, dataframe2 = None):\n",
    "\n",
    "    scored_results = dataframe1[['PatientID', 'Scored Labels', 'Scored Probabilities']]\n",
    "    scored_results.rename(columns={'Scored Labels':'DiabetesPrediction',\n",
    "                                'Scored Probabilities':'Probability'},\n",
    "                        inplace=True)\n",
    "    return scored_results\n",
    "    ```\n",
    "\n",
    "  - Connect the output from the **Score Model** module to the **Dataset1** (left-most) input of the Execute Python Script, and connect the output of the **Execute Python Script** module to the **Web Service Output**.\n",
    "\n",
    "8. Verify that your pipeline looks similar to the following:\n",
    "\n",
    "<img src=\"images/visual-inference.png\" width=200 height=200 />\n",
    "\n",
    "9. Run the pipeline as a new experiment named **mslearn-diabetes-inference** on your compute cluster. This may take a while!\n",
    "10. When the pipeline has finished, select the **Execute Python Script** module, and in the settings pane, on the **Output + Logs** tab, visualize the **Result dataset** to see the predicted labels and probabilities for the three patient observations in the input data.\n",
    "\n",
    "Your inference pipeline predicts whether or not patients are at risk for diabetes based on their features. Now you're ready to publish the pipeline so that client applications can use it.\n",
    "\n",
    "<hr></hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRypURnsjZ3U"
   },
   "source": [
    "**<center><h1>Deploy a predictive service</h1></center>**\n",
    "\n",
    "After you've created and tested an inference pipeline for real-time inferencing, you can publish it as a service for client applications to use.\n",
    "\n",
    "<mark>Note:In this exercise, you'll deploy the web service to an Azure Container Instance (ACI). This type of compute is created dynamically, and is useful for development and testing. For production, you should create an inference cluster, which provide an Azure Kubernetes Service (AKS) cluster that provides better scalability and security.</mark>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwc-cGuSjpmW"
   },
   "source": [
    "**<h2>Deploy a service</h2>**\n",
    "\n",
    "1. View the **Predict Diabetes** inference pipeline you created in the previous unit.\n",
    "2. At the top right, select **Deploy**, and deploy a new real-time endpoint, using the following settings:\n",
    "  - **Name:** predict-diabetes\n",
    "  - **Description:** Classify diabetes.\n",
    "  - **Compute type:** Azure Container Instance\n",
    "3. Wait for the web service to be deployed - this can take several minutes. The deployment status is shown at the top left of the designer interface.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_yUfl5vj9xj"
   },
   "source": [
    "Test the service\n",
    "Now you can test your deployed service from a client application - in this case, you'll use the code in the cell below to simulate a client application.\n",
    "\n",
    "1. On the **Endpoints page**, open the **predict-diabetes** real-time endpoint.\n",
    "\n",
    "2. When the **predict-diabetes** endpoint opens, view the Consume tab and note the following information there. You need this to connect to your deployed service from a client application.\n",
    "\n",
    "The REST endpoint for your service\n",
    "the Primary Key for your service\n",
    "3. Note that you can use the â§‰ link next to these values to copy them to the clipboard.\n",
    "\n",
    "4. With the **Consume** page for the **predict-diabetes** service page open in your browser, open a new browser tab and open a second instance of Azure Machine Learning studio. Then in the new tab, view the **Notebooks** page (under **Author**).\n",
    "\n",
    "5. In the **Notebooks** page, under **My files**, use the ðŸ—‹ button to create a new file with the following settings:\n",
    "\n",
    "  - **File location:** Users/your user name\n",
    " - **File name:** Test-Diabetes.ipynb\n",
    " - **File type:** Notebook\n",
    " - **Overwrite if already exists:** Selected\n",
    "6. When the new notebook has been created, ensure that the compute instance you created previously is selected in the **Compute** box, and that it has a status of **Running**.\n",
    "\n",
    "7. Use the â‰ª button to collapse the file explorer pane and give you more room to focus on the **Test-Diabetes.ipynb** notebook tab.\n",
    "\n",
    "8. In the rectangular cell that has been created in the notebook, paste the following code:\n",
    "\n",
    "```\n",
    "endpoint = 'YOUR_ENDPOINT' #Replace with your endpoint\n",
    "key = 'YOUR_KEY' #Replace with your key\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "\n",
    "data = {\n",
    "    \"Inputs\": {\n",
    "        \"WebServiceInput0\":\n",
    "        [\n",
    "            {\n",
    "                    'PatientID': 1882185,\n",
    "                    'Pregnancies': 9,\n",
    "                    'PlasmaGlucose': 104,\n",
    "                    'DiastolicBloodPressure': 51,\n",
    "                    'TricepsThickness': 7,\n",
    "                    'SerumInsulin': 24,\n",
    "                    'BMI': 27.36983156,\n",
    "                    'DiabetesPedigree': 1.3504720469999998,\n",
    "                    'Age': 43\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    \"GlobalParameters\":  {\n",
    "    }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ key)}\n",
    "\n",
    "req = urllib.request.Request(endpoint, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "    result = response.read()\n",
    "    json_result = json.loads(result)\n",
    "    output = json_result[\"Results\"][\"WebServiceOutput0\"][0]\n",
    "    print('Patient: {}\\nPrediction: {}\\nProbability: {:.2f}'.format(output[\"PatientID\"],\n",
    "                                                            output[\"DiabetesPrediction\"],\n",
    "                                                            output[\"Probability\"]))\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers to help debug\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n",
    "```\n",
    "\n",
    "<mark>Note: Don't worry too much about the details of the code. It just defines features for a patient, and uses the predict-diabetes service you created to predict a diabetes diagnosis.</mark>\n",
    "\n",
    "9. Switch to the browser tab containing the **Consume** page for the **predict-diabetes** service, and copy the REST endpoint for your service. The switch back to the tab containing the notebook and paste the key into the code, replacing YOUR_ENDPOINT.\n",
    "\n",
    "10. Switch to the browser tab containing the **Consume** page for the **predict-diabetes** service, and copy the Primary Key for your service. The switch back to the tab containing the notebook and paste the key into the code, replacing YOUR_KEY.\n",
    "\n",
    "11. Save the notebook. Then use the â–· button next to the cell to run the code.\n",
    "\n",
    "12. Verify that predicted diabetes diagnosis is returned.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUT3kaRElD3z"
   },
   "source": [
    "**<center><h1>Summary</h1></center>**\n",
    "\n",
    "In this module, you learned how to use Azure Machine Learning designer to train and publish a classification model.\n",
    "\n",
    "**<h2>Clean-up</h2>**\n",
    "\n",
    "The web service you created is hosted in an Azure Container Instance. If you don't intend to experiment with it further, you should delete the endpoint to avoid accruing unnecessary Azure usage. You should also stop the compute instance until you need it again.\n",
    "\n",
    "1. In Azure Machine Learning studio, on the **Endpoints** tab, select the **predict-diabetes** endpoint. Then select **Delete** (ðŸ—‘) and confirm that you want to delete the endpoint.\n",
    "2. On the **Compute** page, on the **Compute Instances** tab, select your compute instance and then select **Stop**.\n",
    "\n",
    "<mark>Note:</mark>\n",
    "\n",
    "<mark>Stopping your compute ensures your subscription won't be charged for compute resources. You will however be charged a small amount for data storage as long as the Azure Machine Learning workspace exists in your subscription. If you have finished exploring Azure Machine Learning, you can delete the Azure Machine Learning workspace and associated resources. However, if you plan to complete any other labs in this series, you will need to recreate it.</mark>\n",
    "\n",
    "<mark>To delete your workspace:</mark>\n",
    "\n",
    "<mark>1. In the Azure portal, in the Resource groups page, open the resource group you specified when creating your Azure Machine Learning workspace.</mark>\n",
    "<mark>2. Click Delete resource group, type the resource group name to confirm you want to delete it, and select Delete.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdUbNpehl0t4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course2_Module3CreateAClassificationModelWithAzureMachineLearningDesigner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
