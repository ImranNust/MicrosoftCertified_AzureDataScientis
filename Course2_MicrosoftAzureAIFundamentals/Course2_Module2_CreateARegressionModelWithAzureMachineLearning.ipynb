{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec0aa3b",
   "metadata": {},
   "source": [
    "<center><h1> Create a Regression Model with Azure Machine Learning </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0abf90b",
   "metadata": {},
   "source": [
    "<center><h2> Introduction </h2></center>\n",
    "\n",
    "Regression is a form of machine learning that is used to predict a numeric label based on an item's features. For example, an automobile sales company might use the characteristics of a car (such as engine size, number of seats, mileage, and so on) to predict its likely selling price. In this case, the characteristics of the car are the features, and the selling price is the label.\n",
    "\n",
    "<img src = \"images/image13.png\" width = 1000 height = 1000 />\n",
    "\n",
    "Regression is an example of a supervised machine learning technique in which you train a model using data that includes both the features and known values for the label, so that the model learns to fit the feature combinations to the label. Then, after training has been completed, you can use the trained model to predict labels for new items for which the label is unknown.\n",
    "\n",
    "You can use Microsoft Azure Machine Learning designer to create regression models by using a drag and drop visual interface, without needing to write any code.\n",
    "\n",
    "In this module, you'll learn how to:\n",
    "\n",
    "    - Use Azure Machine Learning designer to train a regression model.\n",
    "    - Use a regression model for inferencing.\n",
    "    - Deploy a regression model as a service.\n",
    "    \n",
    "To complete this module, you'll need a Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at https://azure.microsoft.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660b7b2",
   "metadata": {},
   "source": [
    "<h3> Create an Azure Machine Learning workspace </h3>\n",
    "\n",
    "\n",
    "To use Azure Machine Learning, you create a workspace in your Azure subscription. You can then use this workspace to manage data, compute resources, code, models, and other artifacts related to your machine learning workloads.\n",
    "\n",
    "\n",
    "<mark style=\"background-color: #FFFF00\">Note: This module is one of many that make use of an Azure Machine Learning workspace, including the other modules in the Create no-code predictive models with Azure Machine Learning learning path. If you are using your own Azure subscription, you may consider creating the workspace once and reusing it in other modules. Your Azure subscription will be charged a small amount for data storage as long as the Azure Machine Learning workspace exists in your subscription, so we recommend you delete the Azure Machine Learning workspace when it is no longer required.</mark>\n",
    "\n",
    "\n",
    "**If you don't already have one, follow these steps to create a workspace:**\n",
    "\n",
    "1. Sign into the [Azure portal](https://portal.azure.com/) using the Microsoft credentials associated with your Azure subscription.\n",
    "2. Select **＋Create a resource**, search for Machine Learning, and create a new Machine Learning resource the following settings:\n",
    "    - **Subscription:** Your Azure subscription\n",
    "    - **Resource group:** Create or select a resource group\n",
    "    - **Workspace name:** Enter a unique name for your workspace\n",
    "    - **Region:** Select the geographical region closest to you\n",
    "    - **Storage account:** Note the default new storage account that will be created for your workspace\n",
    "    - **Key vault:** Note the default new key vault that will be created for your workspace\n",
    "    - **Application insights:** Note the default new application insights resource that will be created for your workspace\n",
    "    - **Container registry:** None (one will be created automatically the first time you deploy a model to a container)\n",
    "\n",
    "\n",
    "3. Wait for your workspace to be created (it can take a few minutes). Then go to it in the portal.\n",
    "4. On the Overview page for your workspace, launch Azure Machine Learning studio (or open a new browser tab and navigate to https://ml.azure.com), and sign into Azure Machine Learning studio using your Microsoft account. If prompted, select your Azure directory and subscription, and your Azure Machine Learning workspace.\n",
    "5. In Azure Machine Learning studio, toggle the ☰ icon at the top left to view the various pages in the interface. You can use these pages to manage the resources in your workspace.\n",
    "\n",
    "You can manage your workspace using the Azure portal, but for data scientists and Machine Learning operations engineers, Azure Machine Learning studio provides a more focused user interface for managing workspace resources.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56345ce2",
   "metadata": {},
   "source": [
    "<center> <h2>Create compute resources </h2></center>\n",
    "\n",
    "To train and deploy models using Azure Machine Learning designer, you need compute targets to run the training process. You will also use these compute targets to test the trained model after its deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f533ecd",
   "metadata": {},
   "source": [
    "<h3> Create a compute targets </h3>\n",
    "\n",
    "Compute targets are cloud-based resources on which you can run model training and data exploration processes.\n",
    "\n",
    "In [Azure Machine Learning studio](https://ml.azure.com/), view the **Compute** page (under **Manage**). This is where you manage the compute targets for your data science activities. There are four kinds of compute resource you can create:\n",
    "\n",
    "- **Compute Instances:** Development workstations that data scientists can use to work with data and models.\n",
    "- **Compute Clusters:** Scalable clusters of virtual machines for on-demand processing of experiment code.\n",
    "- **Inference Clusters:** Deployment targets for predictive services that use your trained models.\n",
    "- **Attached Compute:** Links to existing Azure compute resources, such as Virtual Machines or Azure Databricks clusters.\n",
    "\n",
    "\n",
    "<mark style=\"background-color: #FFFF00\">Note: Compute instances and clusters are based on standard Azure virtual machine images. For this module, the Standard_DS11_v2 image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.</mark>\n",
    "\n",
    "1. On the **Compute Clusters** tab, and add a new compute cluster with the following settings. You'll use this to train a machine learning model:\n",
    "    - **Location:** Select the same as your workspace. If that location is not listed, choose the one closest to you\n",
    "    - **Virtual Machine tier:** Dedicated\n",
    "    - **Virtual Machine type:** CPU\n",
    "    - **Virtual Machine size:**\n",
    "        - Choose **Select from all options**\n",
    "        - Search for and select **Standard_DS11_v2**\n",
    "    - **Compute name:** enter a unique name\n",
    "    - **Minimum number of nodes:** 0\n",
    "    - **Maximum number of nodes:** 2\n",
    "    - **Idle seconds before scale down:** 120\n",
    "    - **Enable SSH access:** Unselected\n",
    "\n",
    "<mark style=\"background-color: #FFFF00\"> **Tip:** After you finish the entire module, be sure to follow the Clean Up instructions at the end of the module to stop your compute resources. Stop your compute resources to ensure your subscription won't be charged.</mark>\n",
    "\n",
    "The compute cluster will take some time to be created. You can move onto the next unit while you wait.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8bde5e",
   "metadata": {},
   "source": [
    "<h2> Explore data </h2>\n",
    "\n",
    "To train a regression model, you need a dataset that includes historical features, characteristics of the entity for which you want to make a prediction. You also need known label values, the numeric value that you want to train a model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ad5a0",
   "metadata": {},
   "source": [
    "<h3> Create a pipeline </h3>\n",
    "\n",
    "To use the Azure Machine Learning designer, you create a pipeline that you use to train a machine learning model. This pipeline starts with the dataset from which you want to train the model.\n",
    "\n",
    "1. In Azure Machine Learning studio, view the **Designer** page (under **Author**), and select + to create a new pipeline.\n",
    "2. At the top left-hand side of the screen, click on the default pipeline name (**Pipeline-Created-on-date**) and change it to **Auto Price Training**.\n",
    "3. You must specify a compute target on which to run the pipeline. In the **Settings** pane, click on **Select compute target** to select the compute cluster you created previously (if the **Settings** pane is not visible, select the ⚙ icon next to the pipeline name at the top)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37ce65",
   "metadata": {},
   "source": [
    "<h3> Add and explore a dataset </h3>\n",
    "\n",
    "In this module, you train a regression model that predicts the price of an automobile based on its characteristics. Azure Machine Learning includes a sample dataset that you can use for this model.\n",
    "\n",
    "1. Next to the pipeline name on the left, select the button >> to expand the panel. Find the **Sample datasets** section, and drag the **Automobile price data (Raw)** dataset from the **Samples** section onto the canvas.\n",
    "2. Right-click (Ctrl+click on a Mac) the **Automobile price data (Raw)** dataset on the canvas, and on the **Outputs** menu, click **Dataset output** on the Preview data graph icon.\n",
    "3. Review the schema of the data. Note that you can see the distributions of the various columns as histograms.\n",
    "4. Scroll to the right of the dataset until you see the **Price** column, which is the label that your model predicts.\n",
    "5. Select the column header for the **price** column and view the details that are displayed in the pane to the right. These include various statistics for the column values, and a histogram with the distribution of the column values.\n",
    "6. Scroll back to the left and select the **normalized-losses** column header. Then review the statistics for this column. Note there are quite a few missing values in this column. Missing values limit the column's usefulness for predicting the price label so you might want to exclude it from training.\n",
    "7. View the statistics for the **bore, stroke, and horsepower** columns. Note the number of missing values. These columns have fewer missing values than **normalized-losses**, so they might still be useful in predicting **price** once you exclude the rows where the values are missing from training.\n",
    "8. Compare the values in the **stroke, peak-rpm**, and **city-mpg** columns. These columns are all measured in different scales, and it is possible that the larger values for **peak-rpm** might bias the training algorithm and create an over-dependency on this column compared to columns with lower values, such as **stroke**. Typically, data scientists mitigate this possible bias by normalizing the numeric columns so they're on the similar scales.\n",
    "9. Close the **Automobile price data (Raw)** result visualization window so that you can see the dataset on the canvas like this:\n",
    "\n",
    "<img src = \"images/image14.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7dc20a",
   "metadata": {},
   "source": [
    "<h3> Add data transformations </h3>\n",
    "\n",
    "\n",
    "You typically apply data transformations to prepare the data for modeling. In the case of the automobile price data, you add transformations to address the issues you identified when you explored the data.\n",
    "\n",
    "1. In the pane on the left, expand the **Data Transformation** section, which contains a wide range of modules you can use to transform data before model training.\n",
    "2. Drag a **Select Columns in Dataset module** to the canvas, below the **Automobile price data (Raw)** module. Then connect the output at the bottom of the **Automobile price data (Raw)** module to the input at the top of the **Select Columns in Dataset module**, like this:\n",
    "\n",
    "<img src = \"images/image15.png\" width = 1000 height = 1000/>\n",
    "\n",
    "\n",
    "3. Select the **Select Columns in Dataset module**, and in its **Settings** pane on the right, select **Edit column**. Then in the **Select columns** window, select **By name** and use the + links to add all columns other than **normalized-losses**, like this:\n",
    "\n",
    "<img src = \"images/image16.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00100608",
   "metadata": {},
   "source": [
    "In the rest of this exercise, you go through steps to create a pipeline that looks like this:\n",
    "\n",
    "<img src = \"images/image17.png\" width = 1000 height = 1000/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3c4a4",
   "metadata": {},
   "source": [
    "Follow the remaining steps, use the image for reference as you add and configure the required modules.\n",
    "\n",
    "4. Drag a **Clean Missing Data** module from the **Data Transformations** section, and place it under the **Select Columns in Dataset** module. Then connect the output from the **Select Columns in Dataset** module to the input of the Clean Missing Data module.\n",
    "5. Select the **Clean Missing Data module**, and in the settings pane on the right, click **Edit column**. Then in the **Select columns** window, select **With rules**, in the **Include** list select **Column names**, in the box of column names enter **bore, stroke, and horsepower** like this:\n",
    "\n",
    "<img src = \"images/image18.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f65614",
   "metadata": {},
   "source": [
    "6. With the **Clean Missing Data** module still selected, in the settings pane, set the following configuration settings:\n",
    "- **Minimum missing value ratio:** 0.0\n",
    "- **Maximum missing value ratio:** 1.0\n",
    "- **Cleaning mode:** Remove entire row\n",
    "\n",
    "7. Drag a **Normalize Data** module to the canvas, below the **Clean Missing Data** module. Then connect the left-most output from the **Clean Missing Data** module to the input of the **Normalize Data** module.\n",
    "8. Select the **Normalize Data** module and view its settings. Note that it requires you to specify the transformation method and the columns to be transformed. Then, set the transformation to **MinMax**. Apply a rule to edit the columns to include the following **Column names**:\n",
    "\n",
    "- **symboling**\n",
    "- **wheel-base**\n",
    "- **length**\n",
    "- **width**\n",
    "- **height**\n",
    "- **curb-weight**\n",
    "- **engine-size**\n",
    "- **bore**\n",
    "- **stroke**\n",
    "- **compression-ratio**\n",
    "- **horsepower**\n",
    "- **peak-rpm**\n",
    "- **city-mpg**\n",
    "- **highway-mpg**\n",
    "\n",
    "<img src = \"images/image19.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba344820",
   "metadata": {},
   "source": [
    "<h3> Run the pipeline </h3>\n",
    "\n",
    "To apply your data transformations, you must run the pipeline as an experiment.\n",
    "\n",
    "1. Ensure that your pipeline looks similar to this image:\n",
    "\n",
    "<img src = \"images/image20.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac069b",
   "metadata": {},
   "source": [
    "2. Select **Submit**, and run the pipeline as a new experiment named **mslearn-auto-training** on your compute cluster.\n",
    "Wait for the run to finish, which might take 5 minutes or more. When the run has completed, the modules should look like this:\n",
    "\n",
    "<img src = \"images/image21.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc0ddb",
   "metadata": {},
   "source": [
    "<h3> View the transformed data </h3>\n",
    "\n",
    "The dataset is now prepared for model training.\n",
    "\n",
    "1. Select the completed **Normalize Data** module, and in its **Settings** pane on the right, on the **Outputs + logs** tab, select the **Preview data** icon for the **Transformed dataset**.\n",
    "2. View the data. Note that the **normalized-losses** column has been removed, all rows contain data for **bore, stroke,** and **horsepower**, and the numeric columns you selected have been normalized to a common scale.\n",
    "3. Close the normalized data result visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124fe5f8",
   "metadata": {},
   "source": [
    "<center> <h2> Create and run a training pipeline </h2></center>\n",
    "\n",
    "After you've used data transformations to prepare the data, you can use it to train a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafbd3b",
   "metadata": {},
   "source": [
    "<h3> Add training modules </h3>\n",
    "It's common practice to train the model using a subset of the data, while holding back some data with which to test the trained model. This enables you to compare the labels that the model predicts with the actual known labels in the original dataset.\n",
    "\n",
    "In this exercise, you're going to work through steps to extend the **Auto Price Training** pipeline as shown here:\n",
    "\n",
    "<img src = \"images/image22.png\" width = 1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91469f",
   "metadata": {},
   "source": [
    "Follow the steps below, using the image above for reference as you add and configure the required modules.\n",
    "\n",
    "1. Open the **Auto Price Training** pipeline you created in the previous unit if it's not already open.\n",
    "\n",
    "2. In the pane on the left, in the **Data Transformations** section, drag a **Split Data** module onto the canvas under the **Normalize Data** module. Then connect the Transformed Dataset (left) output of the **Normalize Data** module to the input of the **Split Data** module.\n",
    "\n",
    "3. Select the **Split Data** module, and configure its settings as follows:\n",
    "\n",
    "**Splitting mode:** Split Rows\n",
    "**Fraction of rows in the first output dataset:** 0.7\n",
    "**Random seed:** 123\n",
    "**Stratified split:** False\n",
    "\n",
    "4. Expand the **Model Training** section in the pane on the left, and drag a **Train Model** module to the canvas, under the **Split Data** module. Then connect the Result dataset1 (left) output of the **Split Data** module to the Dataset (right) input of the Train Model module.\n",
    "\n",
    "5. The model we're training will predict the **price** value, so select the **Train Model** module and modify its settings to set the **Label column** to **price** (matching the case and spelling exactly!)\n",
    "\n",
    "6. The **price** label the model will predict is a numeric value, so we need to train the model using a regression algorithm. Expand the **Machine Learning Algorithms** section, and under **Regression**, drag a **Linear Regression** module to the canvas, to the left of the **Split Data** module and above the **Train Model** module. Then connect its output to the **Untrained model** (left) input of the **Train Model** module.\n",
    "\n",
    "**Note:** There are multiple algorithms you can use to train a regression model. For help choosing one, take a look at the Machine Learning Algorithm Cheat Sheet for Azure Machine Learning designer.\n",
    "\n",
    "7. To test the trained model, we need to use it to score the validation dataset we held back when we split the original data - in other words, predict labels for the features in the validation dataset. Expand the **Model Scoring & Evaluation** section and drag a **Score Model** module to the canvas, below the **Train Model** module. Then connect the output of the **Train Model** module to the **Trained model** (left) input of the **Score Model** module; and drag the Results dataset2 (right) output of the **Split Data** module to the **Dataset** (right) input of the Score Model module.\n",
    "8. Ensure your pipeline looks like this:\n",
    "\n",
    "<img src = \"images/image23.png\" width = 1000 height = 1000/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b20b11",
   "metadata": {},
   "source": [
    "<h3> Run the training pipeline </h3>\n",
    "\n",
    "Now you're ready to run the training pipeline and train the model.\n",
    "\n",
    "1. Select **Submit**, and run the pipeline using the existing experiment named **mslearn-auto-training**.\n",
    "2. Wait for the experiment run to complete. This may take 5 minutes or more.\n",
    "3. When the experiment run has completed, select the **Score Model** module and in the settings pane, on the **Outputs + logs** tab, under **Data outputs** in the **Scored dataset** section, use the **Preview Data** icon to view the results.\n",
    "4. Scroll to the right, and note that next to the **price** column (which contains the known true values of the label) there is a new column named **Scored labels**, which contains the predicted label values.\n",
    "5. Close the **Score Model result visualization** window.\n",
    "\n",
    "The model is predicting values for the price label, but how reliable are its predictions? To assess that, you need to evaluate the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
