{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRuXfkGXAVd0"
   },
   "source": [
    "**<center><h1>Introduction</h1></center>**\n",
    "\n",
    "Deep learning is an advanced form of machine learning that tries to emulate the way the human brain learns.\n",
    "\n",
    "In your brain, you have nerve cells called neurons, which are connected to one another by nerve extensions that pass electrochemical signals through the network.\n",
    "\n",
    "<img src = \"images/human-brain.png\" />\n",
    "\n",
    "When the first neuron in the network is stimulated, the input signal is processed, and if it exceeds a particular threshold, the neuron is activated and passes the signal on to the neurons to which it is connected. These neurons in turn may be activated and pass the signal on through the rest of the network. Over time, the connections between the neurons are strengthened by frequent use as you learn how to respond effectively. For example, if someone throws a ball towards you, your neuron connections enable you to process the visual information and coordinate your movements to catch the ball. If you perform this action repeatedly, the network of neurons involved in catching a ball will grow stronger as you learn how to be better at catching a ball.\n",
    "\n",
    "Deep learning emulates this biological process using artificial neural networks that process numeric inputs rather than electrochemical stimuli.\n",
    "\n",
    "<img src = \"images/artificial-neural-network.png\" />\n",
    "\n",
    "The incoming nerve connections are replaced by numeric inputs that are typically identified as x. When there's more than one input value, $x$ is considered a vector with elements named $x1$, $x2$, and so on.\n",
    "\n",
    "Associated with each x value is a weight ($w$), which is used to strengthen or weaken the effect of the x value to simulate learning. Additionally, a bias ($b$) input is added to enable fine-grained control over the network. During the training process, the $w$ and $b$ values will be adjusted to tune the network so that it \"learns\" to produce correct outputs.\n",
    "\n",
    "The neuron itself encapsulates a function that calculates a weighted sum of $x$, $w$, and $b$. This function is in turn enclosed in an activation function that constrains the result (often to a value between 0 and 1) to determine whether or not the neuron passes an output onto the next layer of neurons in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlFBJyYvBHaC"
   },
   "source": [
    "**<center><h1>Deep neural network concepts</h1></center>**\n",
    "\n",
    "Before exploring how to train a deep neural network (DNN) machine learning model, let's consider what we're trying to achieve. Machine learning is concerned with predicting a label based on some features of a particular observation. In simple terms, a machine learning model is a function that calculates $y$ (the label) from $x$ (the features): $f(x)=y$.\n",
    "\n",
    "**<h2>A simple classification example</h2>**\n",
    "\n",
    "For example, suppose your observation consists of some measurements of a penguin.\n",
    "\n",
    "<img src = \"images/penguin.png\" />\n",
    "\n",
    "Specifically, the measurements are:\n",
    "\n",
    "- The length of the penguin's bill.\n",
    "- The depth of the penguin's bill.\n",
    "- The length of the penguin's flipper.\n",
    "- The penguin's weight.\n",
    "\n",
    "In this case, the features $(x)$ are a vector of four values, or mathematically, $x=[x_1,x_2,x_3,x_4]$.\n",
    "\n",
    "Let's suppose that the label we're trying to predict $(y)$ is the species of the penguin, and that there are three possible species it could be:\n",
    "\n",
    "0. Adelie\n",
    "1. Gentoo\n",
    "2. Chinstrap\n",
    "\n",
    "\n",
    "This is an example of a classification problem, in which the machine learning model must predict the most probable class to which the observation belongs. A classification model accomplishes this by predicting a label that consists of the probability for each class. In other words, y is a vector of three probability values; one for each of the possible classes: $y=[P(0),P(1),P(2)]$.\n",
    "\n",
    "You train the machine learning model by using observations for which you already know the true label. For example, you may have the following feature measurements for an Adelie specimen:\n",
    "\n",
    "$x=[37.3, 16.8, 19.2, 30.0]$\n",
    "\n",
    "You already know that this is an example of an Adelie (class 0), so a perfect classification function should result in a label that indicates a 100% probability for class 0, and a 0% probability for classes 1 and 2:\n",
    "\n",
    "$y=[1, 0, 0]$\n",
    "\n",
    "**<h2>A deep neural network model</h2>**\n",
    "\n",
    "So how would we use deep learning to build a classification model for the penguin classification model? Let's look at an example:\n",
    "\n",
    "<img src = \"images/deep-neural-network.png\"  />\n",
    "\n",
    "The deep neural network model for the classifier consists of multiple layers of artificial neurons. In this case, there are four layers:\n",
    "\n",
    "- An input layer with a neuron for each expected input (x) value.\n",
    "- Two so-called hidden layers, each containing five neurons.\n",
    "- An output layer containing three neurons - one for each class probability (y) value to be predicted by the model.\n",
    "\n",
    "Because of the layered architecture of the network, this kind of model is sometimes referred to as a multilayer perceptron. Additionally, notice that all neurons in the input and hidden layers are connected to all neurons in the subsequent layers - this is an example of a fully connected network.\n",
    "\n",
    "When you create a model like this, you must define an input layer that supports the number of features your model will process, and an output layer that reflects the number of outputs you expect it to produce. You can decide how many hidden layers you want to include and how many neurons are in each of them; but you have no control over the input and output values for these layers - these are determined by the model training process.\n",
    "\n",
    "**<h2>Training a deep neural network</h2>**\n",
    "\n",
    "The training process for a deep neural network consists of multiple iterations, called epochs. For the first epoch, you start by assigning random initialization values for the weight (w) and bias b values. Then the process is as follows:\n",
    "\n",
    "1. Features for data observations with known label values are submitted to the input layer. Generally, these observations are grouped into batches (often referred to as mini-batches).\n",
    "2. The neurons then apply their function, and if activated, pass the result onto the next layer until the output layer produces a prediction.\n",
    "3. The prediction is compared to the actual known value, and the amount of variance between the predicted and true values (which we call the loss) is calculated.\n",
    "4. Based on the results, revised values for the weights and bias values are calculated to reduce the loss, and these adjustments are backpropagated to the neurons in the network layers.\n",
    "5. The next epoch repeats the batch training forward pass with the revised weight and bias values, hopefully improving the accuracy of the model (by reducing the loss).\n",
    "\n",
    "<mark>Note: Processing the training features as a batch improves the efficiency of the training process by processing multiple observations simultaneously as a matrix of features with vectors of weights and biases. Linear algebraic functions that operate with matrices and vectors also feature in 3D graphics processing, which is why computers with graphic processing units (GPUs) provide significantly better performance for deep learning model training than central processing unit (CPU) only computers.</mark>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UYcWv-nBQOs"
   },
   "source": [
    "**<h2>A closer look at loss functions and backpropagation</h2>**\n",
    "\n",
    "The previous description of the deep learning training process mentioned that the loss from the model is calculated and used to adjust the weight and bias values. How exactly does this work?\n",
    "\n",
    "**<h3>Calculating loss</h2>**\n",
    "\n",
    "Suppose one of the samples passed through the training process contains features of an Adelie specimen (class 0). The correct output from the network would be $[1, 0, 0]$. Now suppose that the output produced by the network is $[0.4, 0.3, 0.3]$. Comparing these, we can calculate an absolute variance for each element (in other words, how far is each predicted value away from what it should be) as $[0.6, 0.3, 0.3]$.\n",
    "\n",
    "In reality, since we're actually dealing with multiple observations, we typically aggregate the variance - for example by squaring the individual variance values and calculating the mean, so we end up with a single, average loss value, like 0.18.\n",
    "\n",
    "**<h3>Optimizers</h2>**\n",
    "\n",
    "Now, here's the clever bit. The loss is calculated using a function, which operates on the results from the final layer of the network, which is also a function. The final layer of network operates on the outputs from the previous layers, which are also functions. So in effect, the entire model from the input layer right through to the loss calculation is just one big nested function. Functions have a few really useful characteristics, including:\n",
    "\n",
    "- You can conceptualize a function as a plotted line comparing its output with each of its variables.\n",
    "- You can use differential calculus to calculate the derivative of the function at any point with respect to its variables.\n",
    "\n",
    "Let's take the first of these capabilities. We can plot the line of the function to show how an individual weight value compares to loss, and mark on that line the point where the current weight value matches the current loss value.\n",
    "\n",
    "<img src=\"images/loss-plot.png\" />\n",
    "\n",
    "Now let's apply the second characteristic of a function. The derivative of a function for a given point indicates whether the slope (or gradient) of the function output (in this case, loss) is increasing or decreasing with respect to a function variable (in this case, the weight value). A positive derivative indicates that the function is increasing, and a negative derivative indicates that it is decreasing. In this case, at the plotted point for the current weight value, the function has a downward gradient. In other words, increasing the weight will have the effect of decreasing the loss.\n",
    "\n",
    "We use an optimizer to apply this same trick for all of the weight and bias variables in the model and determine in which direction we need to adjust them (up or down) to reduce the overall amount of loss in the model. There are multiple commonly used optimization algorithms, including stochastic gradient descent (SGD), Adaptive Learning Rate (ADADELTA), Adaptive Momentum Estimation (Adam), and others; all of which are designed to figure out how to adjust the weights and biases to minimize loss.\n",
    "\n",
    "\n",
    "\n",
    "**<h3>Learning rate</h2>**\n",
    "\n",
    "Now, the obvious next question is, by how much should the optimizer adjust the weights and bias values? If you look at the plot for our weight value, you can see that increasing the weight by a small amount will follow the function line down (reducing the loss), but if we increase it by too much, the function line starts to go up again, so we might actually increase the loss; and after the next epoch, we might find we need to reduce the weight.\n",
    "\n",
    "The size of the adjustment is controlled by a parameter that you set for training called the learning rate. A low learning rate results in small adjustments (so it can take more epochs to minimize the loss), while a high learning rate results in large adjustments (so you might miss the minimum altogether).\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2IrAOnwDz3u"
   },
   "source": [
    "**<center><h1>Exercise - Train a deep neural network</h1></center>**\n",
    "\n",
    "\n",
    "So far in this module, you've learned a lot about the theory and principles of deep learning with neural networks. The best way to learn how to apply this theory is to actually build a deep learning model, and that's what you'll do in this exercise.\n",
    "\n",
    "There are many frameworks available for training deep neural networks, and in this exercise you can choose to explore either (or both) of two of the most popular deep learning frameworks for Python: PyTorch and TensorFlow.\n",
    "\n",
    "\n",
    "\n",
    "**<h2>Before you start</h2>**\n",
    "\n",
    "To complete the exercise, you'll need:\n",
    "\n",
    "A Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at https://azure.microsoft.com/free.\n",
    "An Azure Machine Learning workspace with a compute instance and the ml-basics repository cloned.\n",
    "\n",
    "<mark>Note: This module makes use of an Azure Machine Learning workspace. If you are completing this module in preparation for the Azure Data Scientist certification, consider creating the workspace once, and reusing it in other modules. After completing the exercise, be sure to follow the Clean Up instructions to stop compute resources, and retain the workspace if you plan to reuse it.</mark>\n",
    "\n",
    "**<h2>Create an Azure Machine Learning workspace</h2>**\n",
    "\n",
    "If you don't already have an Azure Machine Learning workspace in your Azure subscription, follow these steps to create one:\n",
    "\n",
    "1. Sign into the [Azure portal](https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize?redirect_uri=https%3A%2F%2Fportal.azure.com%2Fsignin%2Findex%2F&response_type=code%20id_token&scope=https%3A%2F%2Fmanagement.core.windows.net%2F%2Fuser_impersonation%20openid%20email%20profile&state=OpenIdConnect.AuthenticationProperties%3DrZjD5wWRdY1CxUEU3pr8Lx73Y0K9-MYyqPQKJyWYmJ-e84H4blzIN-W46oVZn3bhvYrXCTiqTaQN8DgkEwrErx8okfgcufaUoYczRPr6lgYQTPEnPspuHqhEupCQdPNojY4OC3z5x3cSev1RanHAfu3bm5V2zBHVbL9is1Epyb34A5hBYWt91GV5oE60T-f-WB7EPk7GHsPR4WUvCiRutTNWqcYKvBvF9U2XNiUQFLuWxgIW9aTbYmIrI01vwOv05Hql267LwrlfWw-6JWUY4XSwjczofOHjyCY4uXoF64TfyX-BjrLrE83bdzKRZ-PRSrXnNv_Q_p6Er-rdFWGOjvffjvw0_N4qtgbUmSj6X5I9J4MBvtHeMMlfLVRVvJp0OrdiIRjg6Rklbd3SipoKxA&response_mode=form_post&nonce=637836071483650548.NzcxODQxMjUtZWM5NC00OTg2LWJjNmYtYjA3YmMxMDkyODViZTQ4OWUwOTItZDI5MS00MGE1LWIzNzktODMxYWNiMjA3YzNh&client_id=c44b4083-3bb0-49c1-b47d-974e53cbdf3c&site_id=501430&client-request-id=c9029c42-b8ae-4c34-894e-f5087e777224&x-client-SKU=ID_NET472&x-client-ver=6.12.2.0) using the Microsoft account associated with your Azure subscription.\n",
    "\n",
    "2. On the Azure **Home** page, under **Azure services**, select **Create a resource**. The **Create a resource** pane appears.\n",
    "\n",
    "3. In the Search services and marketplace search box, search for and select Machine Learning. The **Machine Learning** pane appears.\n",
    "\n",
    "4. Select **Create**. The **Machine learning** pane appears.\n",
    "\n",
    "5. On the **Basics** tab, Enter the following values to each setting.\n",
    "\n",
    "<img src=\"images/image25.png\" />\n",
    "\n",
    "6. Accept the remaining defaults, and select **Review + create**.\n",
    "\n",
    "7. After validation passes, select **Create**.\n",
    "\n",
    "Wait for your workspace resource to be created as it can take a few minutes.\n",
    "\n",
    "8. When deployment completes, select **Go to resource**. Your **Machine learning** pane appears.\n",
    "\n",
    "9. Select **Launch studio**, or go to https://ml.azure.com, and sign in using your Microsoft account. The **Microsoft Azure Machine Learning Studio** page appears.\n",
    "\n",
    "10. In Azure Machine Learning Studio, toggle the ☰ icon at the top left to expane/collapse its menu pane. You can use these options to manage the resources in your workspace.\n",
    "\n",
    "**<h2>Create a compute instance</h2>**\n",
    "\n",
    "To run the notebook used in this exercise, you will need a compute instance in your Azure Machine Learning workspace.\n",
    "\n",
    "1. In the left menu pane, under **Manage**, select **Compute**. The **Compute** pane appears.\n",
    "\n",
    "2. On the **Compute Instances** tab, if you already have a compute instance, start it; otherwise, create a new compute instance by selecting **New**. The **Create compute instance **pane appears.\n",
    "\n",
    "3. Enter the following values for each setting:\n",
    "\n",
    "  - **Compute name:** enter a unique name\n",
    "  - **Virtual machine type:** CPU\n",
    "  - **Virtual machine size:** Select from recommended options: Standard_DS11_v2\n",
    "4. Select **Create**. The **Compute** pane reappears with your Compute instance listed.\n",
    "\n",
    "5. Wait for the compute instance to start as this may take a couple of minutes. Under the **State** column, your Compute instance will change to **Running**.\n",
    "\n",
    "\n",
    "\n",
    "**<h2>Clone the ml-basics repository</h2>**\n",
    "\n",
    "The files used in this module, and other related modules, are published in the **MicrosoftDocs/ml-basics** GitHub repository. If you haven't already done so, use the following steps to clone the repository to your Azure Machine Learning workspace:\n",
    "\n",
    "1. Under the **Applications** column, select the **Jupyter** link to open Jupyter Notebooks in a new browser tab. The **jupyter** pane appears.\n",
    "\n",
    "2. On the menu bar to the far right, select **New**, and from the dropdown list, select **Terminal**. A terminal shell appears.\n",
    "\n",
    "Run the following commands to change the current directory to the **Users** directory, and clone the **ml-basics** repository, which contains the notebook and files you will use in this exercise.\n",
    "\n",
    "```\n",
    "cd Users\n",
    "git clone https://github.com/microsoftdocs/ml-basics\n",
    "```\n",
    "\n",
    "After the command has completed and the checkout of the files is done, close the terminal tab and view the home page in your Jupyter notebook file explorer.\n",
    "\n",
    "Open the Users folder - it should contain an ml-basics folder, containing the files you will use in this module.\n",
    "\n",
    "<mark>Note: We highly recommend using Jupyter in an Azure Machine Learning workspace for this exercise. This setup ensures the correct version of Python and the various packages you will need are installed; and after creating the workspace once, you can reuse it in other modules. If you prefer to complete the exercise in a Python environment on your own computer, you can do so. You'll find details for configuring a local development environment that uses Visual Studio Code at Running the labs on your own computer. Be aware that if you choose to do this, the instructions in the exercise may not match your notebooks user interface.</mark>\n",
    "\n",
    "**<h2>Train a deep neural network model</h2>**\n",
    "\n",
    "After you've created a Jupyter environment, and cloned the ml-basics repository, you're ready to explore deep learning.\n",
    "\n",
    "1. In Jupyter, in the ml-basics folder, open either the **Deep Neural Networks (PyTorch).ipynb** or **Deep Neural Networks (Tensorflow).ipynb** notebook, depending on your framework preference, and follow the instructions it contains.\n",
    "\n",
    "2. When you've finished, close and halt all notebooks.\n",
    "\n",
    "When you've finished working through the notebook, return to this module and move on to the next unit to learn more.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YN0Zw7kGgvb"
   },
   "source": [
    "**<center><h1>Convolutional neural networks</h1></center>**\n",
    "\n",
    "While you can use deep learning models for any kind of machine learning, they're particularly useful for dealing with data that consists of large arrays of numeric values - such as images. Machine learning models that work with images are the foundation for an area artificial intelligence called computer vision, and deep learning techniques have been responsible for driving amazing advances in this area over recent years.\n",
    "\n",
    "At the heart of deep learning's success in this area is a kind of model called a convolutional neural network, or CNN. A CNN typically works by extracting features from images, and then feeding those features into a fully connected neural network to generate a prediction. The feature extraction layers in the network have the effect of reducing the number of features from the potentially huge array of individual pixel values to a smaller feature set that supports label prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BqWzX2CGtHX"
   },
   "source": [
    "**<h2>Layers in a CNN</h2>**\n",
    "\n",
    "CNNs consist of multiple layers, each performing a specific task in extracting features or predicting labels.\n",
    "\n",
    "\n",
    "**<h3>Convolution layers</h3>**\n",
    "\n",
    "One of the principal layer types is a convolutional layer that extracts important features in images. A convolutional layer works by applying a filter to images. The filter is defined by a kernel that consists of a matrix of weight values.\n",
    "\n",
    "For example, a $3\\times3$ filter might be defined like this:\n",
    "\n",
    "```\n",
    "1  -1   1\n",
    "-1   0  -1\n",
    "1  -1   1\n",
    "```\n",
    "An image is also just a matrix of pixel values. To apply the filter, you \"overlay\" it on an image and calculate a weighted sum of the corresponding image pixel values under the filter kernel. The result is then assigned to the center cell of an equivalent 3x3 patch in a new matrix of values that is the same size as the image. For example, suppose a $6\\times6$ image has the following pixel values:\n",
    "\n",
    "```\n",
    "255 255 255 255 255 255 \n",
    "255 255 100 255 255 255\n",
    "255 100 100 100 255 255\n",
    "100 100 100 100 100 255\n",
    "255 255 255 255 255 255\n",
    "255 255 255 255 255 255\n",
    "```\n",
    "\n",
    "Applying the filter to the top-left $3\\times3$ patch of the image would work like this:\n",
    "\n",
    "```\n",
    "255 255 255      1  -1   1    (255 x 1)+(255 x -1)+(255 x 1) +\n",
    "255 255 100  x  -1   0  -1  = (255 x -1)+(255 x 0)+(100 x -1) +   = 155\n",
    "255 100 100      1  -1   1    (255 x1 )+(100 x -1)+(100 x 1)\n",
    "```\n",
    "\n",
    "The result is assigned to the corresponding pixel value in the new matrix like this:\n",
    "\n",
    "```\n",
    "?   ?   ?   ?   ?   ?  \n",
    " ?  155  ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    "```\n",
    "\n",
    "Now the filter is moved along (convolved), typically using a step size of 1 (so moving along one pixel to the right), and the value for the next pixel is calculated\n",
    "\n",
    "```\n",
    "255 255 255      1  -1   1    (255 x 1)+(255 x -1)+(255 x 1) +\n",
    "255 100 255  x  -1   0  -1  = (255 x -1)+(100 x 0)+(255 x -1) +   = -155\n",
    "100 100 100      1  -1   1    (100 x1 )+(100 x -1)+(100 x 1)\n",
    "```\n",
    "\n",
    "So now we can fill in the next value of the new matrix.\n",
    "\n",
    "```\n",
    "?   ?   ?   ?   ?   ?  \n",
    " ?  155 -155 ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    " ?   ?   ?   ?   ?   ?\n",
    "```\n",
    "\n",
    "The process repeats until we've applied the filter across all of the 3x3 patches of the image to produce a new matrix of values like this:\n",
    "\n",
    "```\n",
    "?   ?   ?    ?    ?   ?\n",
    "?  155 -155 155 -155  ?\n",
    "? -155 310 -155  155  ?\n",
    "?  310 155  310   0   ?\n",
    "? -155 -155 -155  0   ?\n",
    "?   ?   ?    ?    ?   ?\n",
    "```\n",
    "\n",
    "Because of the size of the filter kernel, we can't calculate values for the pixels at the edge; so we typically just apply a padding value (often 0):\n",
    "\n",
    "```\n",
    "0   0   0    0    0   0\n",
    "0  155 -155 155 -155  0\n",
    "0 -155 310 -155  155  0\n",
    "0  310 155  310   0   0\n",
    "0 -155 -155 -155  0   0\n",
    "0   0   0    0    0   0\n",
    "```\n",
    "\n",
    "The output of the convolution is typically passed to an activation function, which is often a Rectified Linear Unit (ReLU) function that ensures negative values are set to 0:\n",
    "\n",
    "\n",
    "```\n",
    "0   0   0    0    0   0\n",
    "0  155  0   155   0   0\n",
    "0   0  310   0   155  0\n",
    "0  310 155  310   0   0\n",
    "0   0   0    0    0   0\n",
    "0   0   0    0    0   0\n",
    "```\n",
    "\n",
    "The resulting matrix is a feature map of feature values that can be used to train a machine learning model.\n",
    "\n",
    "<mark>Note: The values in the feature map can be greater than the maximum value for a pixel (255), so if you wanted to visualize the feature map as an image you would need to normalize the feature values between 0 and 255.</mark>\n",
    "\n",
    "The convolution process is shown in the animation below.\n",
    "\n",
    "<img src=\"images/convolution.gif\"  />\n",
    "\n",
    "1. An image is passed to the convolutional layer. In this case, the image is a simple geometric shape.\n",
    "2. The image is composed of an array of pixels with values between 0 and 255 (for color images, this is usually a 3-dimensional array with values for red, green, and blue channels).\n",
    "3. A filter kernel is generally initialized with random weights (in this example, we've chosen values to highlight the effect that a filter might have on pixel values; but in a real CNN, the initial weights would typically be generated from a random Gaussian distribution). This filter will be used to extract a feature map from the image data.\n",
    "4. The filter is convolved across the image, calculating feature values by applying a sum of the weights multiplied by their corresponding pixel values in each position. A Rectified Linear Unit (ReLU) activation function is applied to ensure negative values are set to 0.\n",
    "5. After convolution, the feature map contains the extracted feature values, which often emphasize key visual attributes of the image. In this case, the feature map highlights the edges and corners of the triangle in the image.\n",
    "\n",
    "Typically, a convolutional layer applies multiple filter kernels. Each filter produces a different feature map, and all of the feature maps are passed onto the next layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC_U6IWVGx5s"
   },
   "source": [
    "**<h3>Pooling layers</h3>**\n",
    "\n",
    "After extracting feature values from images, pooling (or downsampling) layers are used to reduce the number of feature values while retaining the key differentiating features that have been extracted.\n",
    "\n",
    "One of the most common kinds of pooling is max pooling in which a filter is applied to the image, and only the maximum pixel value within the filter area is retained. So for example, applying a 2x2 pooling kernel to the following patch of an image would produce the result 155.\n",
    "\n",
    "```\n",
    "0   0\n",
    "0  155\n",
    "```\n",
    "\n",
    "Note that the effect of the 2x2 pooling filter is to reduce the number of values from 4 to 1.\n",
    "\n",
    "As with convolutional layers, pooling layers work by applying the filter across the whole feature map. The animation below shows an example of max pooling for an image map.\n",
    "\n",
    "<img src=\"images/pooling.gif\" />\n",
    "\n",
    "A filter kernel is convolved across an image of a triangle, extracting features that emphasize the three edges and corners, max pooling for an image map.\n",
    "\n",
    "1. The feature map extracted by a filter in a convolutional layer contains an array of feature values.\n",
    "2. A pooling kernel is used to reduce the number of feature values. In this case, the kernel size is 2x2, so it will produce an array with quarter the number of feature values.\n",
    "3. The pooling kernel is convolved across the feature map, retaining only the highest pixel value in each position.\n",
    "\n",
    "**<h3>Dropping layers</h3>**\n",
    "\n",
    "One of the most difficult challenges in a CNN is the avoidance of overfitting, where the resulting model performs well with the training data but doesn't generalize well to new data on which it wasn't trained. One technique you can use to mitigate overfitting is to include layers in which the training process randomly eliminates (or \"drops\") feature maps. This may seem counterintuitive, but it's an effective way to ensure that the model doesn't learn to be over-dependent on the training images.\n",
    "\n",
    "Other techniques you can use to mitigate overfitting include randomly flipping, mirroring, or skewing the training images to generate data that varies between training epochs.\n",
    "\n",
    "**<h3>Flattening layers</h3>**\n",
    "\n",
    "After using convolutional and pooling layers to extract the salient features in the images, the resulting feature maps are multidimensional arrays of pixel values. A flattening layer is used to flatten the feature maps into a vector of values that can be used as input to a fully connected layer.\n",
    "\n",
    "**<h3>Fully connected layers</h3>**\n",
    "\n",
    "Usually, a CNN ends with a fully connected network in which the feature values are passed into an input layer, through one or more hidden layers, and generate predicted values in an output layer.\n",
    "\n",
    "A basic CNN architecture might look similar to this:\n",
    "\n",
    "<img src = \"images/convolutional-neural-network.png\"  />\n",
    "\n",
    "1. Images are fed into a convolutional layer. In this case, there are two filters, so each image produces two feature maps.\n",
    "2. The feature maps are passed to a pooling layer, where a 2x2 pooling kernel reduces the size of the feature maps.\n",
    "3. A dropping layer randomly drops some of the feature maps to help prevent overfitting.\n",
    "4. A flattening layer takes the remaining feature map arrays and flattens them into a vector.\n",
    "5. The vector elements are fed into a fully connected network, which generates the predictions. In this case, the network is a classification model that predicts probabilities for three possible image classes (triangle, square, and circle).\n",
    "\n",
    "\n",
    "**<h2>Training a CNN model</h2>**\n",
    "\n",
    "As with any deep neural network, a CNN is trained by passing batches of training data through it over multiple epochs, adjusting the weights and bias values based on the loss calculated for each epoch. In the case of a CNN, backpropagation of adjusted weights includes filter kernel weights used in convolutional layers as well as the weights used in fully connected layers.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD4yTOd8KsF2"
   },
   "source": [
    "**<center><h1>Exercise - Train a convolutional neural network</h1></center>**\n",
    "\n",
    "PyTorch and TensorFlow both offer comprehensive support for building convolutional neural networks as classification models for images.\n",
    "\n",
    "1. In this exercise, you'll use your preferred framework to create a simple CNN-based image classifier for images of simple geometric shapes. The same principles can be applied to images of any kind.\n",
    "\n",
    "To complete the exercise:\n",
    "\n",
    "In Jupyter, in the **ml-basics** folder, open the **Convolutional Neural Networks (PyTorch).ipynb** or **Convolutional Neural Networks (Tensorflow).ipynb** notebook, depending on your framework preference, and follow the instructions it contains.\n",
    "\n",
    "When you've finished, close and halt all notebooks.\n",
    "\n",
    "When you've finished working through the notebook, return to this module and move on to the next unit to learn more.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLQ3peRILpaJ"
   },
   "source": [
    "**<center><h1>Transfer learning\n",
    "Completed</h1></center>**\n",
    "\n",
    "In life, it’s often easier to learn a new skill if you already have expertise in a similar, transferrable skill. For example, it’s probably easier to teach someone how to drive a bus if they have already learned how to drive a car. The driver can build on the driving skills they've already learned in a car, and apply them to driving a bus.\n",
    "\n",
    "The same principle can be applied to training deep learning models through a technique called transfer learning.\n",
    "\n",
    "**<h2>How transfer learning works</h2>**\n",
    "\n",
    "A Convolutional Neural Network (CNN) for image classification is typically composed of multiple layers that extract features, and then use a final fully connected layer to classify images based on these features.\n",
    "\n",
    "<img src=\"images/transfer-learning.png\"  />\n",
    "\n",
    "Conceptually, this neural network consists of two distinct sets of layers:\n",
    "\n",
    "1. A set of layers from the base model that perform feature extraction.\n",
    "2. A fully connected layer that takes the extracted features and uses them for class prediction.\n",
    "\n",
    "The feature extraction layers apply convolutional filters and pooling to emphasize edges, corners, and other patterns in the images that can be used to differentiate them, and in theory should work for any set of images with the same dimensions as the input layer of the network. The prediction layer maps the features to a set of outputs that represent probabilities for each class label you want to use to classify the images.\n",
    "\n",
    "By separating the network into these types of layers, we can take the feature extraction layers from a model that has already been trained and append one or more layers to use the extracted features for prediction of the appropriate class labels for your images. This approach enables you to keep the pre-trained weights for the feature extraction layers, which means you only need to train the prediction layers you have added.\n",
    "\n",
    "There are many established convolutional neural network architectures for image classification that you can use as the base model for transfer learning, so you can build on the work someone else has already done to easily create an effective image classification model.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCNzpX4uMJJ_"
   },
   "source": [
    "**<center><h1>Exercise - Use transfer learning</h1></center>**\n",
    "\n",
    "PyTorch and TensorFlow both support a library of existing models that you can use as the basis for transfer learning.\n",
    "\n",
    "In this exercise, you'll use your preferred framework to train a convolutional neural network model by using transfer learning.\n",
    "\n",
    "To complete the exercise:\n",
    "\n",
    "1. In Jupyter, in the **ml-basics** folder, open either the **Transfer Learning (PyTorch).ipynb** or **Transfer Learning (Tensorflow).ipynb** notebook, depending on your framework preference, and follow the instructions it contains.\n",
    "\n",
    "2. When you've finished, close and halt all notebooks.\n",
    "\n",
    "**<h2>Clean-up</h2>**\n",
    "\n",
    "If you used a compute instance in an Azure Machine Learning workspace to complete the exercises, use these steps to clean up.\n",
    "\n",
    "1. Close all Jupyter notebooks and the Jupyter home page.\n",
    "\n",
    "2. In Azure Machine Learning Studio, on the **Compute page**, select your compute instance, and in the top menu bar, select **Stop**.\n",
    "\n",
    "If you don't intend to complete other modules that require the Azure Machine Learning workspace, you can delete the resource group you created for it from your Azure subscription.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZsjAjP5MmGm"
   },
   "source": [
    "**<center><h1>Summary</h1></center>**\n",
    "\n",
    "In this module you learned about the fundamental principles of deep learning, and how to create deep neural network models using PyTorch or Tensorflow. You also explored the use of convolutional neural networks to create image classification models.\n",
    "\n",
    "Deep learning techniques are at the cutting edge of machine learning and artificial intelligence, and are used to implement enterprise solutions. If this module has inspired you to build machine learning solutions, you should consider learning how Azure Machine Learning can help you train, deploy, and manage models at scale. You can learn how to use Azure Machine Learning to manage machine learning operations in the [Build AI solutions with Azure Machine Learning service](https://docs.microsoft.com/en-us/learn/paths/build-ai-solutions-with-azure-ml-service/) learning path.\n",
    "\n",
    "<hr></hr>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Course1_Module5TrainAndEvaluateDeepLearningModels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
