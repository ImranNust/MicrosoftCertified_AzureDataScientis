{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course3_Module4WorkWithComputeInAzureMachineLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Introduction</h1></center>**\n",
        "\n",
        "In Azure Machine Learning, data scientists can run experiments based on scripts that process data, train machine learning models, and perform other data science tasks. The runtime context for each experiment run consists of two elements:\n",
        "\n",
        "- The environment for the script, which includes all packages on which the script depends.\n",
        "- The compute target on which the environment will be deployed and the script run.\n",
        "\n",
        "**<h2>Learning objectives</h2>**\n",
        "\n",
        "In this module, you will learn how to:\n",
        "\n",
        "- Create and use environments.\n",
        "- Create and use compute targets.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "Wc_79hyqeW1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Introduction to environments</h1></center>**\n",
        "\n",
        "<img src=\"images/05-compute-contexts.png\"/>\n",
        "\n",
        "Python code runs in the context of a virtual environment that defines the version of the Python runtime to be used as well as the installed packages available to the code. In most Python installations, packages are installed and managed in environments using **Conda** or **pip**.\n",
        "\n",
        "To improve portability, we usually create environments in docker containers that are in turn be hosted in compute targets, such as your development computer, virtual machines, or clusters in the cloud.\n",
        "\n",
        "**<h2>Environments in Azure Machine Learning</h2>**\n",
        "\n",
        "In general, Azure Machine Learning handles environment creation and package installation for you - usually through the creation of Docker containers. You can specify the Conda or pip packages you need, and have Azure Machine Learning create an environment for the experiment.\n",
        "\n",
        "In an enterprise machine learning solution, where experiments may be run in a variety of compute contexts, it can be important to be aware of the environments in which your experiment code is running. Environments are encapsulated by the **Environment** class; which you can use to create environments and specify runtime configuration for an experiment.\n",
        "\n",
        "You can have Azure Machine Learning manage environment creation and package installation to define an environment, and then register it for reuse. Alternatively, you can manage your own environments and register them. This makes it possible to define consistent, reusable runtime contexts for your experiments - regardless of where the experiment script is run.\n",
        "\n",
        "\n",
        "\n",
        "**<h2>Creating environments</h2>**\n",
        "\n",
        "There are multiple ways to create environments in Azure Machine Learning.\n",
        "\n",
        "**<h3>Creating an environment from a specification file</h3>**\n",
        "\n",
        "You can use a Conda or pip specification file to define the packages required in a Python environment, and use it to create an **Environment** object.\n",
        "\n",
        "For example, you could save the following Conda configuration settings in a file named **conda.yml**:\n",
        "\n",
        "```\n",
        "# Bash\n",
        "name: py_env\n",
        "dependencies:\n",
        "  - numpy\n",
        "  - pandas\n",
        "  - scikit-learn\n",
        "  - pip:\n",
        "    - azureml-defaults\n",
        "```\n",
        "You could then use the following code to create an Azure Machine Learning environment from the saved specification file:\n",
        "\n",
        "```\n",
        "# Python\n",
        "from azureml.core import Environment\n",
        "\n",
        "env = Environment.from_conda_specification(name='training_environment',\n",
        "                                           file_path='./conda.yml')\n",
        "```\n",
        "\n",
        "\n",
        "**<h3>Creating an environment from an existing Conda environment</h3>**\n",
        "\n",
        "If you have an existing Conda environment defined on your workstation, you can use it to define an Azure Machine Learning environment:\n",
        "\n",
        "\n",
        "```\n",
        "# Python\n",
        "from azureml.core import Environment\n",
        "\n",
        "env = Environment.from_existing_conda_environment(name='training_environment',\n",
        "                                                  conda_environment_name='py_env')\n",
        "```\n",
        "\n",
        "\n",
        "**<h3>Creating an environment by specifying packages</h3>**\n",
        "\n",
        "You can define an environment by specifying the Conda and pip packages you need in a **CondaDependencies** object, like this:\n",
        "```\n",
        "# Python\n",
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "env = Environment('training_environment')\n",
        "deps = CondaDependencies.create(conda_packages=['scikit-learn','pandas','numpy'],\n",
        "                                pip_packages=['azureml-defaults'])\n",
        "env.python.conda_dependencies = deps\n",
        "```\n",
        "\n",
        "**<h2>Configuring environment containers</h2>**\n",
        "\n",
        "Usually, environments for experiment script are created in containers. The following code configures a script-based experiment to host the env environment created previously in a container (this is the default unless you use a **DockerConfiguration** with a **use_docker** attribute of **False**, in which case the environment is created directly in the compute target)\n",
        "```\n",
        "# Python\n",
        "from azureml.core import Experiment, ScriptRunConfig\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "\n",
        "docker_config = DockerConfiguration(use_docker=True)\n",
        "\n",
        "script_config = ScriptRunConfig(source_directory='my_folder',\n",
        "                                script='my_script.py',\n",
        "                                environment=env,\n",
        "                                docker_runtime_config=docker_config)\n",
        "```\n",
        "Azure Machine Learning uses a library of base images for containers, choosing the appropriate base for the compute target you specify (for example, including Cuda support for GPU-based compute). If you have created custom container images and registered them in a container registry, you can override the default base images and use your own by modifying the attributes of the environment's **docker** property..\n",
        "```\n",
        "# Python\n",
        "env.docker.base_image='my-base-image'\n",
        "env.docker.base_image_registry='myregistry.azurecr.io/myimage'\n",
        "```\n",
        "Alternatively, you can have an image created on-demand based on the base image and additional settings in a dockerfile.\n",
        "```\n",
        "# Python\n",
        "env.docker.base_image = None\n",
        "env.docker.base_dockerfile = './Dockerfile'\n",
        "```\n",
        "By default, Azure machine Learning handles Python paths and package dependencies. If your image already includes an installation of Python with the dependencies you need, you can override this behavior by setting **python.user_managed_dependencies** to **True** and setting an explicit Python path for your installation.\n",
        "```\n",
        "# Python\n",
        "env.python.user_managed_dependencies=True\n",
        "env.python.interpreter_path = '/opt/miniconda/bin/python'\n",
        "```\n",
        "\n",
        "**<h2>Registering and reusing environments</h2>**\n",
        "\n",
        "After you've created an environment, you can register it in your workspace and reuse it for future experiments that have the same Python dependencies.\n",
        "\n",
        "**<h3>Registering an environment</h3>**\n",
        "\n",
        "Use the **register** method of an **Environment** object to register an environment:\n",
        "```\n",
        "# Python\n",
        "env.register(workspace=ws)\n",
        "```\n",
        "You can view the registered environments in your workspace like this:\n",
        "\n",
        "```\n",
        "# Python\n",
        "from azureml.core import Environment\n",
        "\n",
        "env_names = Environment.list(workspace=ws)\n",
        "for env_name in env_names:\n",
        "    print('Name:',env_name)\n",
        "```\n",
        "**<h3>Retrieving and using an environment</h3>**\n",
        "\n",
        "You can retrieve a registered environment by using the **get** method of the **Environment** class, and then assign it to a **ScriptRunConfig**.\n",
        "\n",
        "For example, the following code sample retrieves the training_environment registered environment, and assigns it to a script run configuration:\n",
        "```\n",
        "# Python\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "\n",
        "training_env = Environment.get(workspace=ws, name='training_environment')\n",
        "\n",
        "script_config = ScriptRunConfig(source_directory='my_folder',\n",
        "                                script='my_script.py',\n",
        "                                environment=training_env)\n",
        "```\n",
        "When an experiment based on the estimator is run, Azure Machine Learning will look for an existing environment that matches the definition, and if none is found a new environment will be created based on the registered environment specification.\n",
        "\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "Oxg3lzAWelt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Introduction to compute targets</h1></center>**\n",
        "\n",
        "In Azure Machine Learning, Compute Targets are physical or virtual computers on which experiments are run.\n",
        "\n",
        "**<h2>Types of compute</h2>**\n",
        "\n",
        "Azure Machine Learning supports multiple types of compute for experimentation and training. This enables you to select the most appropriate type of compute target for your particular needs.\n",
        "\n",
        "- **Local compute** - You can specify a local compute target for most processing tasks in Azure Machine Learning. This runs the experiment on the same compute target as the code used to initiate the experiment, which may be your physical workstation or a virtual machine such as an Azure Machine Learning compute instance on which you are running a notebook. Local compute is generally a great choice during development and testing with low to moderate volumes of data.\n",
        "- **Compute clusters** - For experiment workloads with high scalability requirements, you can use Azure Machine Learning compute clusters; which are multi-node clusters of Virtual Machines that automatically scale up or down to meet demand. This is a cost-effective way to run experiments that need to handle large volumes of data or use parallel processing to distribute the workload and reduce the time it takes to run.\n",
        "- **Attached compute** - If you already use an Azure-based compute environment for data science, such as a virtual machine or an Azure Databricks cluster, you can attach it to your Azure Machine Learning workspace and use it as a compute target for certain types of workload.\n",
        " \n",
        "<mark>Note: In Azure Machine Learning studio, you can create another type of compute named inference clusters. This kind of compute represents an Azure Kubernetes Service cluster and can only be used to deploy trained models as inferencing services. We'll explore deployment later, but for now we'll focus on compute for experiments and model training.</mark>\n",
        "\n",
        "The ability to assign experiment runs to specific compute targets helps you implement a flexible data science ecosystem in the following ways:\n",
        "\n",
        "- Code can be developed and tested on local or low-cost compute, and then moved to more scalable compute for production workloads.\n",
        "- You can run individual processes on the compute target that best fits its needs. For example, by using GPU-based compute to train deep learning models, and switching to lower-cost CPU-only compute to test and register the trained model.\n",
        "\n",
        "One of the core benefits of cloud computing is the ability to manage costs by paying only for what you use. In Azure Machine Learning, you can take advantage of this principle by defining compute targets that:\n",
        "\n",
        "- Start on-demand and stop automatically when no longer required.\n",
        "- Scale automatically based on workload processing needs.\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "Mttgwv-fvyHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Create compute targets<h1></center>**\n",
        "\n",
        "\n",
        "The most common ways to create or attach a compute target are to use the Compute page in Azure Machine Learning studio, or to use the Azure Machine Learning SDK to provision compute targets in code.\n",
        "\n",
        "**<h2>Creating a managed compute target with the SDK</h2>**\n",
        "\n",
        " A managed compute target is one that is managed by Azure Machine Learning, such as an Azure Machine Learning compute cluster.\n",
        "\n",
        "To create an Azure Machine Learning compute cluster, use the **azureml.core.compute.ComputeTarget** class and the **AmlCompute** class, like this:\n",
        "```\n",
        "#Python\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Specify a name for the compute (unique within the workspace)\n",
        "compute_name = 'aml-cluster'\n",
        "\n",
        "# Define compute configuration\n",
        "compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',\n",
        "                                                       min_nodes=0, max_nodes=4,\n",
        "                                                       vm_priority='dedicated')\n",
        "\n",
        "# Create the compute\n",
        "aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
        "aml_cluster.wait_for_completion(show_output=True)\n",
        "```\n",
        "In this example, a cluster with up to four nodes that is based on the STANDARD_DS12_v2 virtual machine image will be created. The priority for the virtual machines (VMs) is set to dedicated, meaning they are reserved for use in this cluster (the alternative is to specify lowpriority, which has a lower cost but means that the VMs can be preempted if a higher-priority workload requires the compute).\n",
        "\n",
        "\n",
        "**<h2>Attaching an unmanaged compute target with the SDK</h2>**\n",
        "\n",
        "An unmanaged compute target is one that is defined and managed outside of the Azure Machine Learning workspace; for example, an Azure virtual machine or an Azure Databricks cluster.\n",
        "\n",
        "The code to attach an existing unmanaged compute target is similar to the code used to create a managed compute target, except that you must use the **ComputeTarget.attach()** method to attach the existing compute based on its target-specific configuration settings.\n",
        "\n",
        "For example, the following code can be used to attach an existing Azure Databricks cluster:\n",
        "```\n",
        "#Python\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Specify a name for the compute (unique within the workspace)\n",
        "compute_name = 'db_cluster'\n",
        "\n",
        "# Define configuration for existing Azure Databricks cluster\n",
        "db_workspace_name = 'db_workspace'\n",
        "db_resource_group = 'db_resource_group'\n",
        "db_access_token = '1234-abc-5678-defg-90...'\n",
        "db_config = DatabricksCompute.attach_configuration(resource_group=db_resource_group,\n",
        "                                                   workspace_name=db_workspace_name,\n",
        "                                                   access_token=db_access_token)\n",
        "\n",
        "# Create the compute\n",
        "databricks_compute = ComputeTarget.attach(ws, compute_name, db_config)\n",
        "databricks_compute.wait_for_completion(True)\n",
        "```\n",
        "\n",
        "\n",
        "**<h2>Checking for an existing compute target</h2>**\n",
        "\n",
        "In many cases, you will want to check for the existence of a compute target, and only create a new one if there isn't already one with the specified name. To accomplish this, you can catch the **ComputeTargetException** exception, like this:\n",
        "```\n",
        "#Python\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "compute_name = \"aml-cluster\"\n",
        "\n",
        "# Check if the compute target exists\n",
        "try:\n",
        "    aml_cluster = ComputeTarget(workspace=ws, name=compute_name)\n",
        "    print('Found existing cluster.')\n",
        "except ComputeTargetException:\n",
        "    # If not, create it\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2',\n",
        "                                                           max_nodes=4)\n",
        "    aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
        "\n",
        "aml_cluster.wait_for_completion(show_output=True)\n",
        "```\n",
        "<hr>"
      ],
      "metadata": {
        "id": "gR0SiiBlwlUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Use compute targets<h1></center>**\n",
        "\n",
        "\n",
        "After you've created or attached compute targets in your workspace, you can use them to run specific workloads; such as experiments.\n",
        "\n",
        "To use a particular compute target, you can specify it in the appropriate parameter for an experiment run configuration or estimator. For example, the following code configures an estimator to use the compute target named aml-cluster:\n",
        "```\n",
        "#Python\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "\n",
        "compute_name = 'aml-cluster'\n",
        "\n",
        "training_env = Environment.get(workspace=ws, name='training_environment')\n",
        "\n",
        "script_config = ScriptRunConfig(source_directory='my_dir',\n",
        "                                script='script.py',\n",
        "                                environment=training_env,\n",
        "                                compute_target=compute_name)\n",
        "```\n",
        "When an experiment is submitted, the run will be queued while the aml-cluster compute target is started and the specified environment created on it, and then the run will be processed on the compute environment.\n",
        "\n",
        "Instead of specifying the name of the compute target, you can specify a ComputeTarget object, like this:\n",
        "```\n",
        "#Python\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "from azureml.core.compute import ComputeTarget\n",
        "\n",
        "compute_name = \"aml-cluster\"\n",
        "\n",
        "training_cluster = ComputeTarget(workspace=ws, name=compute_name)\n",
        "\n",
        "training_env = Environment.get(workspace=ws, name='training_environment')\n",
        "\n",
        "script_config = ScriptRunConfig(source_directory='my_dir',\n",
        "                                script='script.py',\n",
        "                                environment=training_env,\n",
        "                                compute_target=training_cluster)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "H78TPS1sxnU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>Exercise - Work with Compute Contexts</h1></center>**\n",
        "\n",
        "\n",
        "Now it's your chance to work with environments and compute targets in Azure Machine Learning.\n",
        "\n",
        "In this exercise, you will:\n",
        "\n",
        "- Create and use an environment.\n",
        "- Create and use a compute target.\n",
        "\n",
        "**<h2>Instructions</h2>**\n",
        "\n",
        "Follow these instructions to complete the exercise.\n",
        "\n",
        "1. If you do not already have an Azure subscription, sign up for a free trial at https://azure.microsoft.com.\n",
        "2. View the exercise repo at https://aka.ms/mslearn-dp100.\n",
        "3. If you have not already done so, complete the **Create an Azure Machine Learning workspace** exercise to provision an Azure Machine Learning workspace, create a compute instance, and clone the required files.\n",
        "4. Complete the **Work with compute ** exercise."
      ],
      "metadata": {
        "id": "g9ZweiuSjkBG"
      }
    }
  ]
}